\chapter{Circuit Compilers}\label{chap:circuit-compilers}
% finite field arithmetics https://johnkerl.org/doc/ffcomp.pdf
As previously demonstrated in Chapter \ref{sec:statements}, statements in formal languages can be formalized as membership or knowledge claims, with algebraic circuits and Rank-1 Constraint Systems being two crucial means of defining these languages.

However, both algebraic circuits and Rank-1 Constraint Systems present substantial deviations from conventional programming paradigms and present difficulties for developers. The task of writing real-world applications as circuits and verifying them through Rank-1 Constraint Systems is as challenging as writing code in low-level languages such as assembly. To facilitate complex statement design, it is necessary to have a compiler framework that can translate high-level languages into arithmetic circuits and associated Rank-1 Constraint Systems.

These programming languages allow for more intuitive and efficient creation and testing of arithmetic circuits, freeing developers from the intricacies of R1CS representations. As a result, they can concentrate on the logic of the circuits they intend to build while the compiler handles the rest.

An additional benefit of R1CS compiling programming languages is that they can generate not only R1CS representations but also other programs that can efficiently compute the values of the circuit's assignment. This facilitates integration of the circuits into various platforms and environments, without the need to consider underlying implementation details.

As demonstrated in Chapter \ref{sec:statements} through sections \ref{sec:R1CS} and \ref{sec:circuits}, both arithmetic circuits and Rank-1 Constraint Systems exhibit a modular property \ref{sec:R1CS_modularity}, allowing for synthesis of complex circuits from simpler ones. Many circuit/R1CS compilers adopt a basic approach of providing a library of atomic and simple circuits, with a means of combining these building blocks into more complex systems.

This chapter provides an overview of basic concepts in the field of circuit compilers, presenting a toy language which can be manually "compiled" into graphical representations of algebraic circuits and their associated Rank-1 Constraint Systems. The chapter then examines real-world compilers and the higher-level languages they support.

The chapter begins with a general introduction to the toy programming language and to the real world languages, followed by a discussion of atomic types such as booleans and unsigned integers. Control flow primitives, including the if-then-else conditional and the bounded loop, are then defined. The chapter concludes with a review of basic functionality primitives, such as elliptic curve cryptography, commonly referred to as "gadgets" in literature.

\section{A Pen-and-Paper Language} To explain basic concepts of circuit compilers and their associated high-level languages, we derive an informal toy language and associated ``brain-compiler'' which we name \lgname{PAPER} (\textbf{P}en-\textbf{A}nd-\textbf{P}aper \textbf{E}xecution \textbf{R}ules). \lgname{PAPER} allows programmers to define statements in Rust-like pseudo-code. The language is inspired by \lgname{zokrates} and \lgname{circom}.
 
\subsection{The Grammar}
In \lgname{PAPER}, any statement is defined as an ordered list of functions, where any function has to be declared in the list before it is called in another function of that list. The last entry in a statement has to be a special function, called \texttt{main}. Functions take a list of typed parameters as inputs and compute a tuple of typed variables as output, where type\_functions are special functions that define how to transform one type into another type, ultimately transforming any type into elements of the base field where the circuit is defined over. 

Any statement is parameterized over the field that the circuit will be defined on, and has additional optional parameters of unsigned type, needed to define the size of arrays or the counter of bounded loops. The following definition makes the grammar of a statement precise using a command line language like description: 
% used the command line style formalized e.g. here: http://docopt.org/
\begin{lstlisting}
statement <Name> {F:<Field> [ , <N_1: unsigned>,... ] } {
  [fn <Name>([[pub]<Arg>:<Type>,...]) -> (<Type>,...){
    [let [pub] <Var>:<Type> ;... ]
    [let const <Const>:<Type>=<Value> ;... ]
    Var<==(fn([<Arg>|<Const>|<Var>,...])|(<Arg>|<Const>|<Var>)) ;
    return (<Var>,...) ;
  } ;...]
  fn main([[pub]<Arg>:<Type>,...]) -> (<Type>,...){
    [let [pub] <Var>:<Type> ;... ]
    [let const <Const>:<Type>=<Value> ;... ]
    Var<==(fn([<Arg>|<Const>|<Var>,...])|(<Arg>|<Const>|<Var>)) ;
    return (<Var>,...) ;
  } ;
}
\end{lstlisting}
Function arguments and variables are witness variables by default, but can be declared as instance by the \texttt{pub} specifier. Declaring arguments and variables as instances always overwrites any previous or conflicting witness declarations. Every argument, constant or variable has a type, and every type is defined as a function that transforms that type into another type. In order for a \lgname{PAPER} program to compile successfully, all type transformations must be composed in such a way that the final type is the base field where the circuit is defined over: 
\begin{lstlisting}
type_function <TYPE>( t1 : <TYPE_1>) -> TYPE_2{
  let t2: TYPE_2 <== fn(TYPE_1)
  return t2
}
\end{lstlisting}
Many real-world circuit languages are based on a similar, but of course more sophisticated approach than \lgname{PAPER}. The purpose of \lgname{PAPER} is to show basic principles of circuit compilers and their associated high-level languages.
\begin{example}To get a better understanding of the grammar of \lgname{PAPER}, the following constitutes proper high-level code that follows the grammar of the \lgname{PAPER} language, assuming that all types in that code have been defined elsewhere. 
\begin{lstlisting}
statement MOCK_CODE {F: F_43, N_1 = 1024, N_2 = 8} {
  fn foo(in_1 : F, pub in_2 : TYPE_2) -> F {
    let const c_1 : F = 0 ;
    let const c_2 : TYPE_2 = SOME_VALUE ;
    let pub out_1 : F ;
    out_1<== c_1 ;
    return out_1 ;
  } ;
  
  fn bar(pub in_1 : F) -> F {
    let out_1 : F ;
    out_1<==foo(in_1);
    return out_1 ;
  } ;
    
  fn main(in_1 : TYPE_1)->(F, TYPE_2){
    let const c_1 : TYPE_1  = SOME_VALUE ;
    let const c_2 : F = 2;
    let const c_3 : TYPE_2  = SOME_VALUE  ;
    let pub out_1 : F ;
    let out_2 : TYPE_2 ;
    c_1 <== in_1 ;
    out_1 <== foo(c_2) ;
    out_2 <== TYPE_2 ;
    return (out_1,out_2) ;
  } ;
}
\end{lstlisting}
\end{example}
\subsection{The Execution Phases} In contrast to normal executable programs, programs for circuit compilers have two modes of execution. The first mode, usually called the  \term{setup phase}, is executed in order to generate the circuit and its associated Rank-1 Constraint System, the latter of which is then usually used as input to some zero-knowledge proof system as explained in \ref{chapter:zk-protocols}.

The second mode of execution is usually called the \term{prover phase}. In this phase, some assignment to all instance variables of the circuit is usually given as input and the task of a prover is to compute a valid assignment to all witness variables of the circuit. Depending on the use case, this valid assignment is then either directly used as constructive proof for proper circuit execution or is transferred as input to the proof generation algorithm of some zero-knowledge proof system, where the full-sized, non hiding constructive proof is processed into a succinct proof with various levels of zero knowledge.

Modern circuit languages and their associated compilers abstract over those two phases and provide a unified \term{interphase} to the developer, who then writes a single program that can be used in both phases.

To give the reader a clear, conceptual distinction between the two phases, \lgname{PAPER} keeps them separated. \lgname{PAPER}-code can be ``brain-compiled'' during the \term{setup-phase} in a pen-and-paper approach into a graphical circuit representation. Once a circuit is derived, it can be executed in a \term{prover phase} to generate a valid assignment. The valid assignment is then interpreted as a constructive proof for a knowledge claim in the associated language.
\paragraph{The Setup Phase} In \lgname{PAPER}, the task of the setup phase is to compile code in the \lgname{PAPER} language into a visual representation of an algebraic circuit. Deriving the circuit from the code in a pen-and-paper style is what we call \term{brain-compiling}.

Given some statement description that adheres to the correct grammar, we start the graphical circuit compilation process with an empty circuit, compile the main function first and then inductively compile all other functions as they are called during the process. 

For every function that we currently compile, we draw a box-node for every input argument, every variable and every constant of that function. If the node represents a variable, we label it with that variable's name, and if it represents a constant, we label it with that constant's value. We group arguments into a subgraph labeled ``inputs'' and return values into a subgraph labeled ``outputs". We then group everything into a subgraph and label that subgraph with the function's name.

After this is done, we have to do a consistency and type check for every occurrence of the assignment operator \texttt{<==}. We have to ensure that the expression on the right side of the operator is well defined and that the types of both side match.

Then we compile the right side of every occurrence of the assignment operator \texttt{<==}. If the right side is a constant or variable defined in this function, we draw a dotted line from the box-node that represents the left side of \texttt{<==} to the box node that represents the right side of the same operator. If the right side represents an argument of that function we draw a line from the box-node that represents the left side of \texttt{<==} to the box node that represents the right side of the same operator. 

If the right side of the \texttt{<==} operator is a function, we look into our database, find its associated circuit and draw it. If no circuit is  associated to that function yet, we repeat the compilation process for that function, drawing edges from the function's argument to its input nodes and from the functions output nodes to the nodes on the right side of \texttt{<==}.

During that process, edge labels are drawn according to the defining rules of algebraic circuits from \ref{def:algebraic-circuit}. If the associated variable represents a witness variable, we use the $W$ label to indicate a witness, and if it represents a instance variable, we use the $I$ label to indicate an instance. Variables are witnesses by default and the $pub$ specifier indicates that the variable is an instance.

Once this is done, we compile all occurring types of all variables in a function, by compiling the type\_function of each type. We do this inductively until we reach the type of the base field. Circuits have no notion of types, only of field elements; hence, every type needs to be compiled to the field type in a sequence of compilation steps.

The compilation stops once we have inductively replaced all functions by their circuits. The result is a circuit that contains many unnecessary box nodes. In a final \term{optimization step}, all box nodes that are directly linked to each other are collapsed into a single node, and all box nodes that represent the same constants are collapsed into a single node. 

Of course, \lgname{PAPER}'s brain-compiler is not properly defined in any formal manner. Its purpose is to highlight important steps that real-world compilers undergo in their setup phases. 
\begin{example}[A trivial Circuit]\label{ex:trivial-circuit} To give an intuition of how to write and compile circuits in the \lgname{PAPER} language, consider the following statement description:
\begin{lstlisting}
statement trivial_circuit {F:F_13} {
  fn main{F}(in1 : F, pub in2 : F) -> (F,F){
    let const outc1 : F = 0 ;   
    let const inc1 : F = 7 ;
    let out1 : F ;
    let out2 : F ;
    out1 <== inc1;
    out2 <== in1;
    outc1 <== in2;
    return (out1, out2) ;
  }
}
\end{lstlisting} 
To brain-compile this statement into an algebraic circuit with \lgname{PAPER}, we start with an empty circuit and evaluate function \texttt{main}, which is the only function in this statement. 

We draw box-nodes for every argument, every constant and every variable of the function and label them with their names or values, respectively.  Then we do a consistency and type check for every \texttt{<==} operator in the function. Since the circuit only wires inputs to outputs and all elements have the same type, the check is valid.

Then we evaluate the right side of the assignment operators. Since, in our case, the right side of each operator is not a function, we draw edges from the box-nodes on the right side to the associated box node on the left side. To label those edges, we use the general rules of algebraic circuits as defined in \ref{def:algebraic-circuit}. According to those rules, every incoming edge of a sink node has a label and every outgoing edge of a source node has a label, if the node is labeled with a variable. Since nodes that represent constants are implicitly assumed to be private, and since the public specifier determines if an edge is labeled with $W$ or $I$, we get the following circuit:
\begin{center}
\digraph[scale=0.4]{TRIVIAL1}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	subgraph clusterINPUTS {
		n1 [shape=box, label="in_1"];
	  n2 [shape=box, label="in_2 = 0"];
	  color= lightgray ;
	  label = "inputs" ;
	}
	
	subgraph clusterOUTPUTS {
		n4 [shape=box, label="out_1"];
	  n5 [shape=box, label="out_2"];
		color= lightgray ;
	  label = "outputs" ;
	}

  subgraph clusterINNER {
  	n3 [shape=box, label="7"];
	  n6 [shape=box, label="0"];
	  color= white ;
  }
	n1 -> n5 [xlabel="W_1"] ;
	n2 -> n6 [xlabel="0"] ;
	n3 -> n4 ;
}
\end{center}
\end{example}
\paragraph{The Prover Phase} In \lgname{PAPER}, a so-called \term{prover phase} can be executed once the setup phase has generated a graphic circuit representation from its associated high-level code. This is done by executing the circuit while assigning proper values to all input nodes of the circuit. However, in contrast to most real-world compilers, \lgname{PAPER} does not tell the prover how to find proper input values to a given circuit. Real-world programing languages usually provide this data by computations that are done outside of the circuit.
\begin{example} Consider the circuit from \examplename{} \ref{ex:TJJ-circuit_2}. Valid assignments to this circuit are constructive proofs that the pair of inputs $<I_1,I_2>$ is a point on the tiny-jubjub curve. However, the circuit does not provide a way to actually compute proper values for $I_1$ and $I_2$. Any real-world system therefore needs an auxiliary computation that provides those values.
\end{example}
\section{Real World Circuit Languages}
Programming languages that compile to rank-1 constraint systems are becoming increasingly popular in the fields of cryptography and blockchain. These languages provide a higher-level abstraction for designing and implementing arithmetic circuits, which are fundamental building blocks in zero-knowledge proof systems. By using these programming languages, developers can focus on the logic of the circuits they want to build, while the compiler takes care of the low-level details of R1CS representations. Additionally, these languages can output not only the R1CS representation, but also other programs, that can efficiently compute all values of a valid circuit assignment. 

\subsection{Circom}
Circom is a domain-specific programming language for designing arithmetic circuits. It is used to build circuits that can be compiled to rank-1 constraint systems and outputted as WebAssembly and C++ programs for efficient evaluation.

In this section, we will gives examples of how to write basic circuits in Circom. We will use those examples then later to compute associated proof in snarkjs. 

To understand circom, we first have to provide definitions for the terms \hilight{signals},\hilight{templates}, and \hilight{components} to facilitate a better understanding of the examples discussed.

A \term{signal} refers to an element in the underlying finite field $\F$ of a circuit. The arithmetic circuits created using Circom operate on signals, which are immutable and can be defined as inputs or outputs. Input signals are private, unless specified as public, and all output signals are publicly accessible. The remaining signals are private and cannot be made public. Public signals are part of the instance and private signals are part of the witness in any valid assigment of a circuit.

A \term{template} is an algorithm that creates generic circuits in Circom. The template is a new circuit object that can be utilized to construct other circuits.

\term{Components} define an arithmetic circuit by receiving input signals and producing output signals and intermediate signals, as well as a set of constraints. Components, like signals, are also immutable.

\begin{example}
\label{ex:trivial-circuit-circom}
As a demonstration of the generation of circuits in the Circom language, we revisit the trivial circuit from example \ref{ex:trivial-circuit} as previously defined in \lgname{PAPER}. The following code provides one representation of this circuit in the Circom language:

\begin{lstlisting}
template trivial_circuit() {

    signal private input in1 ;
    signal private input in2 ;

    var outc1 = 0 ;
    var inc1 = 7 ;
    
    signal output out1 ;
    signal output out2 ;

    out2 <== in1 ;
    outc1 === in2 ;
}

component main = trivial_circuit() ;
\end{lstlisting}

It should be noted that the underlying field is not made explicit in Circom, thus the constants $0$ and $7$ have no immediate significance. To compile the Circom language into an R1CS representation, the code must be saved as a text file. We refer to it as \fname{trivial\_circuit.circom}. This file can then be compiled using the following command:
\begin{lstlisting}
circom trivial_circuit.circom --r1cs --wasm --sym
\end{lstlisting}

The Circom compiler generates three distinct files. The first file, \fname{trivial\_circuit.r1cs}, contains the R1CS constraint system of the circuit in a custom binary format. The second file, \fname{trivial\_circuit.wasm}, is a wasm code that computes a witness from a given instance, thereby yielding a solution to the R1CS. Finally, the third file, \fname{trivial\_circuit.sym}, is a symbols text file necessary for debugging or annotated printing of the constraint system.
\end{example}

\begin{example}[The 3-factorization problem in Circom]
\label{ex:3-fac-circom}
In this example we implement the 3-factorization problem \ref{ex:3-factorization} in Circom's language and compile into an R1CS and statement generator. In order to show, how Circom handles modularity \ref{modularity}, we write the code as follows:
\begin{lstlisting}
template Multiplier() {
    signal input a ;
    signal input b ;
    signal output c ;
    c <== a*b ;
}


template three_fac () {
    signal input x1 ;
    signal input x2 ;
    signal input x3 ;
    signal output x4 ;
    component mult1 = Multiplier() ;
    component mult2 = Multiplier() ;
    mult1.a <== x1 ;
    mult1.b <== x2 ;
    mult2.a <== mult1.c ;
    mult2.b <== x3 ;
    x4 <== mult2.c ;
}

component main = three_fac() ;
\end{lstlisting}
To compile this Circom implementation into an R1CS representation and statement generator, the code must be saved as a text file. We refer to it as \fname{three\_fac.circom}. This file can then be compiled using the following command:
\begin{lstlisting}
circom three_fac.circom --r1cs --wasm --sym
\end{lstlisting}
Once the file is compiled, the \texttt{info} command can be used to print circuit stats, including the number of constraints:
\begin{lstlisting}
snarkjs r1cs info circuit.r1cs

[INFO]  snarkJS: Curve: bn-128
[INFO]  snarkJS: # of Wires: 6
[INFO]  snarkJS: # of Constraints: 2
[INFO]  snarkJS: # of Private Inputs: 0
[INFO]  snarkJS: # of Public Inputs: 3
[INFO]  snarkJS: # of Labels: 11
[INFO]  snarkJS: # of Outputs: 1
\end{lstlisting}
\end{example}

\section{Common Programing concepts}
In this section, we cover concepts that appear in almost every programming language, and see how they can be implemented in circuit compilers. 
\subsection{Primitive Types} 
% https://zeroknowledge.fm/172-2/ reference for all the languages
Primitive data types like booleans, (unsigned) integers, or strings are the most basic building blocks one can expect to find in every general high-level programing language. In order to write statements as computer programs that compile into circuits, it is therefore necessary to implement primitive types as constraint systems, and define their associated operations as circuits.

In this section, we look at some common ways to achieve this. After a recapitulation of the atomic type for the base field where the circuit is defined on, we start with an implementation of the boolean type and its associated boolean algebra as circuits. After that, we define unsigned integers based on the boolean type, and leave the implementation of signed integers as an exercise to the reader. 

\subsubsection{The base-field type} 
\label{def:base_field_type}
Since both algebraic circuits and their associated Rank-1 Constraint Systems are defined over a finite field, elements from that field are the atomic informational units in those models. In this sense, field elements $x\in \F$ are for algebraic circuits what bits are for computers. 

In \lgname{PAPER}, we write \texttt{F} for this type and specify the actual instance of the field type in curly brackets after the name of a given statement. Two functions are associated to this type, which are induced by the \term{addition} and \term{multiplication} law in the field \texttt{F}. We write
\begin{equation}
\mathtt{MUL}:\; \mathtt{F} \times \mathtt{F} \to \mathtt{F}\;;\; (x,y) \mapsto \mathtt{MUL}(x,y)
\end{equation}
\begin{equation}
\mathtt{ADD}:\; \mathtt{F} \times \mathtt{F} \to \mathtt{F}\;;\; (x,y) \mapsto \mathtt{ADD}(x,y)
\end{equation}
Circuit compilers have to compile these functions into arithmetic gates, as explained in \ref{algebraic-gates}. Every other function has to be expressed in terms of these two atomic functions.

To represent addition and multiplication in the \lgname{PAPER} language, we define the following two functions:
\begin{lstlisting}
fn MUL(x : F, y : F) -> F{}
\end{lstlisting}  
\begin{lstlisting}
fn ADD(x : F, y : F) -> F{}
\end{lstlisting}
The compiler then compiles every occurrence of the $\mathtt{MUL}$ or the $\mathtt{ADD}$ function into the following graphical circuit representations:
\begin{center}
\digraph[scale=0.5]{FNMUL}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 [shape=box, label="x"];
	n2 [shape=box, label="y"];
	n3 [label="*"];	
	n4 [shape=box, label="(x*y)"];
	
	n1 -> n3 [xlabel="W_1"] ;
	n2 -> n3 [xlabel="W_2"];
	n3 -> n4 [xlabel="W_3"] ;
	
	n5 [shape=box, label="x"];
	n6 [shape=box, label="y"];
	n7 [label="+"];	
	n8 [shape=box, label="(x+y)"];
	
	n5 -> n7 [xlabel="W_1"] ;
	n6 -> n7 [xlabel="W_2"];
	n7 -> n8 [xlabel="W_3"] ;
}
\end{center}
\begin{example}[Basic gates] To give an intuition of how a real-world compiler might transform addition and multiplication in algebraic expressions into a circuit, consider the following \lgname{PAPER} statement:
\begin{lstlisting}
statement basic_ops {F:F_13} {
  fn main(in_1 : F, pub in_2 : F) -> (F, F){
  	let out_1 : F ;
	let out_2 : F ;
    out_1 <== MUL(in_1,in_2) ;
    out_2 <== ADD(in_1,in_2) ;
    return (out_1, out_2) ;
  }
}
\end{lstlisting} 
To compile this into an algebraic circuit, we start with an empty circuit and evaluate the function \texttt{main}, which is the only function in this statement. We draw an inputs subgraph containing box-nodes for every argument of the function, and an outputs subgraph containing box-nodes for every factor in the return value. Since all of these nodes represent variables of the \texttt{field} type, we don't have to add any type constraints to the circuit.

We check the validity of every expression on the right side of every \texttt{<==} operator including a type check. In our case, every variable is of the \texttt{field} type and hence the types match the types of the \texttt{MUL} as well as the \texttt{ADD} function and the type of the left sides of \texttt{<==} operators. 

We evaluate the expressions on the right side of every \texttt{<==} operator inductively, replacing every occurrence of a function with a subgraph that represents its associated circuit.

According to \lgname{PAPER}, every occurrence of the instance specifier \texttt{pub} overwrites the associate witness default value. Using the appropriate edge labels we get: 
\begin{center}
\digraph[scale=0.5]{BASICOPS}{
    forcelabels=true;
    //center=true;
    splines=ortho;
    nodesep= 2.0;

    subgraph cluster_input {
        nin1 [shape= box, label="in_1"] ;
        nin2 [shape= box, label="in_2"] ;
        color=lightgray ;
        label="inputs" ;
    }

    subgraph cluster_output {
        nout1 [shape= box, label="out_1"] ;
        nout2 [shape= box, label="out_2"] ;
        color=lightgray ;
        label="outputs" ;
    }

    subgraph cluster_mul {
	    nmul1 [shape=box, label="x"];
	    nmul2 [shape=box, label="y"];
	    nmul3 [label="*"];	
	    nmul4 [shape=box, label="(x*y)"];
	    
	    nmul1 -> nmul3 [xlabel="W_1 "] ;
	    nmul2 -> nmul3 [xlabel="W_2"];
	    nmul3 -> nmul4 [xlabel="W_3 "] ;
        color=lightgray ;
        label="fn MUL" ;
    }
    
    subgraph cluster_add {
	    nadd1 [shape=box, label="x"];
	    nadd2 [shape=box, label="y"];
	    nadd3 [label="+"];	
	    nadd4 [shape=box, label="(x+y)"];
	    
	    nadd1 -> nadd3 [xlabel="W_1"] ;
	    nadd2 -> nadd3 [xlabel="W_2 "];
	    nadd3 -> nadd4 [xlabel="W_3 "] ;
        color=lightgray ;
        label="fn ADD" ;
    }    
    // subgraph connectors
    nin1 -> {nmul1, nadd1} [xlabel="W_1", style=dashed, color=grey] ;  
    nin2 -> {nmul2, nadd2} [xlabel="I_2 ", style=dashed, color=grey] ;
    nmul4 -> nout1 [headlabel="W_3 ", style=dashed, color=grey] ;    
    nadd4 -> nout2 [headlabel="W_4 ", style=dashed, color=grey] ;    
}
\end{center}
Any real-world compiler might process its associated high-level language in a similar way, replacing functions, or gadgets by predefined associated circuits. This process is often followed by various optimization steps that try to reduce the number of constraints as much as possible.

In \lgname{PAPER}, we optimize this circuit by collapsing all box nodes that are directly connected to other box nodes, adhering to the rule that a variable's \texttt{pub} specifier overwrites any witness specifier. Reindexing edge labels, we get the following circuit as our pen and paper compiler output: 
\begin{center}
\digraph[scale=0.5]{BASICOPSOPTI}{
    forcelabels=true;
    //center=true;
    splines=ortho;
    nodesep= 2.0;

    n1 [shape= box, label="in_1"] ;
    n2 [shape= box, label="in_2"] ;
    n3 [shape= box, label="out_1"] ;
    n4 [shape= box, label="out_2"] ;
	n5 [label="*"] ;	
	n6 [label="+"] ;    
	
    n1 -> {n5, n6} [xlabel="W_1"] ;  
    n2 -> {n5, n6} [xlabel="I_2 "] ;
    n5 -> n3 [xlabel="W_3 "] ;    
    n6 -> n4 [label=" W_4"] ;    
}
\end{center}
\end{example} 
\begin{example}[$3$-factorization] Consider our $3$-factorization problem from \examplename{} \ref{ex:3-factorization} and the associated circuit $C_{3.fac\_zk}(\F_{13})$ we provided in \examplename{} \ref{ex:TJJ-circuit_1}. To understand the process of replacing high-level functions by their associated circuits inductively, we want define a \lgname{PAPER} statement that we brain-compile into an algebraic circuit equivalent to $C_{3.fac\_zk}(\F_{13})$:
\begin{lstlisting}
statement 3_fac_zk {F:F_13} {
  fn main(x_1 : F, x_2 : F, x_3 : F) -> F{
	let pub 3_fac_zk : F ;
    f_3.fac_zk <== MUL( MUL( x_1 , x_2 ) , x_3 ) ;
    return 3_fac_zk ;
  }
}
\end{lstlisting} 
Using \lgname{PAPER}, we start with an empty circuit and then add $3$ input nodes to the input subgraph as well as $1$ output node to the output subgraph. All these nodes are decorated with the associated variable names. Since all of these nodes represent variables of the \texttt{field} type, we don't have to add any type constraints to the circuit.

We check the validity of every expression on the right side of the single \texttt{<==} operator including a type check. 

We evaluate the expressions on the right side of every \texttt{<==} operator inductively. We have two nested multiplication functions and we replace them by the associated multiplication circuits, starting with the most outer function. We get: 
\begin{center}
\digraph[scale=0.5]{PAPER3FUC}{
    forcelabels=true;
    //center=true;
    splines=ortho;
    nodesep= 2.0;

    subgraph cluster_input {
        nin1 [shape= box, label="x_1"] ;
        nin2 [shape= box, label="x_2"] ;
        nin3 [shape= box, label="x_3"] ;
        color=lightgray ;
        label="inputs" ;
    }

    subgraph cluster_output {
        nout1 [shape= box, label="f_3.fac_zk"] ;
        color=lightgray ;
        label="outputs" ;
    }

    subgraph cluster_mul1 {
	    nmul11 [shape=box, label="x"];
	    nmul12 [shape=box, label="y"];
	    nmul13 [label="*"];	
	    nmul14 [shape=box, label="(x*y)"];
	    
	    nmul11 -> nmul13 [xlabel="W_1"] ;
	    nmul12 -> nmul13 [xlabel="W_2"];
	    nmul13 -> nmul14 [xlabel="W_3"] ;
        color=lightgray ;
        label="fn MUL" ;
    }
    
    subgraph cluster_mul2 {
	    nmul21 [shape=box, label="x"];
	    nmul22 [shape=box, label="y"];
	    nmul23 [label="*"];	
	    nmul24 [shape=box, label="(x*y)"];
	    
	    nmul21 -> nmul23 [xlabel="W_1"] ;
	    nmul22 -> nmul23 [xlabel="W_2"];
	    nmul23 -> nmul24 [xlabel="W_3"] ;
        color=lightgray ;
        label="fn MUL" ;
    }    
    // subgraph connectors
    nin1 -> nmul11 [xlabel="W_1", style=dashed, color=grey] ;  
    nin2 -> nmul12 [xlabel="W_2", style=dashed, color=grey] ;
    nin3 -> nmul22 [xlabel="W_3", style=dashed, color=grey] ;    
    nmul14 -> nmul21 [xlabel="W_4", style=dashed, color=grey] ;   
    nmul24 -> nout1 [xlabel="I_1", style=dashed, color=grey] ;   
}
\end{center} 
In a final optimization step, we collaps all box nodes directly connected to other box nodes, adhering to the rule that a variables \texttt{public} specifier overwrites any \texttt{private} specifier. Reindexing edge labels we get the following circuit:
\begin{center}
\digraph[scale=0.5]{PAPER3FUCOPTI}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 [shape=box, label="x_1"];
	n2 [shape=box, label="x_2"];
	n3 [shape=box, label="x_3"];
	n4 [shape=box, label="f_3.fac_zk"];
	n5 [label="*"];
	n6 [label="*"];	
	
	n1 -> n5 [xlabel="W_1"] ;
	n2 -> n5 [xlabel="W_2"] ;
	n3 -> n6 [xlabel="W_3"];
	n5 -> n6 [xlabel="W_4"] ;
	n6 -> n4 [xlabel="I_1"];
}
\end{center} 
\end{example}
\paragraph{The Subtraction Constraint System} By definition, algebraic circuits only contain addition and multiplication gates, and it follows that there is no single gate for field subtraction, despite the fact that subtraction is a native operation in every field.

High-level languages and their associated circuit compilers, therefore, need another way to deal with subtraction. To see how this can be achieved, recall that subtraction is defined by addition with the additive inverse, and that the inverse can be computed efficiently by multiplication with $-1$. A circuit for field subtraction is therefore given by
\begin{center}
\digraph[scale=0.4]{BTSUB}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 -> n5 [xlabel="S_1    "];
	n2 -> n4 [xlabel="S_2    "];
	n3 -> n4 ;
	n4 -> n5 ;
	n5 -> n6 [xlabel="S_3    "];
	n1 [shape=box, label="x"];
	n2 [shape=box, label="y"];
	n3 [shape=box, label="-1"];
	n4 [label="*"];	
	n5 [label="+"];
	n6 [shape=box, label="SUB(x,y)"]
}
\end{center}
Using the general method from \ref{sec:circuits_associated_R1CS}, the circuits associated Rank-1 Constraint System is given by:
\begin{equation}
\left(S_1 + (-1)\cdot S_2\right)\cdot 1 = S_3
\end{equation}
Any valid assignment $<S_1,S_2, S_3>$ to this circuit therefore enforces the value $S_3$ to be the difference $S_1- S_2$.

Real-world compilers usually provide a gadget or a function to abstract over this circuit such that programmers can use subtraction as if it were native to circuits.
In \lgname{PAPER}, we define the following subtraction function that compiles to the previous circuit:
\begin{lstlisting}
fn SUB(x : F, y : F) -> F{
  let rslt : F ;
  constant c : F = -1 ;
  rslt <== ADD(x , MUL( y ,  c) );
  return rslt ;
}
\end{lstlisting}
In the setup phase of a statement, we compile every occurrence of the $\mathtt{SUB}$ function into an instance of its associated subtraction circuit, and edge labels are generated according to the rules from \ref{def:algebraic-circuit}.
\paragraph{The Inversion Constraint System} By definition, algebraic circuits only contain addition and multiplication gates, and it follows that there is no single gate for field inversion, despite the fact that inversion is a native operation in every field. 

If the underlying field is a prime field, one approach would be to use Fermat's little theorem \ref{fermats-little-theorem} to compute the multiplicative inverse inside the circuit. To see how this works, let $\F_p$ be the prime field. The multiplicative inverse $x^{-1}$ of a field element $x\in\F$ with $x\neq 0$ is then given by $x^{-1}= x^{p-2}$, and computing $x^{p-2}$ in the circuit therefore computes the multiplicative inverse. 

Unfortunately, real-world primes $p$ are large and computing $x^{p-2}$ by repeated multiplication of $x$ with itself is infeasible. A ``square and multiply'' approach \ref{alg_square-and-mul} is faster, as it computes the power in roughly $log_2(p)$ steps, but still adds a lot of constraints to the circuit. 

Computing inverses in the circuit makes no use of the fact that inversion is a native operation in any field. A more constraints friendly approach is therefore to compute the multiplicative inverse outside of the circuit and then only enforce correctness of the computation in the circuit. 

To understand how this can be achieved, observe that a field element $y\in \F$ is the multiplicative inverse of a field element $x\in \F$ if and only if $x\cdot y =1$ in $\F$. We can use this, and define a circuit that has two inputs, $x$ and $y$, and enforces $x\cdot y =1$. It is then guaranteed that $y$ is the multiplicative inverse of $x$. The price we pay is that we can not compute $y$ by circuit execution, but auxiliary data is needed to tell any prover which value of $y$ is needed for a valid circuit assignment.  The following circuit defines the constraint
\begin{center}
\label{circ:inversion}
\digraph[scale=0.4]{BTINV}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 -> n3 [xlabel="S_1  "];
	n2 -> n3 [xlabel="S_2  "];
	n3 -> n4 [xlabel="S_3 =1  "];
	n1 [shape=box, label="x"];
	n2 [shape=box, label="x^(-1)"];
	n3 [label="*"];	
	n4 [shape=box, label="1"];	
}
\end{center}
Using the general method from \ref{sec:circuits_associated_R1CS}, the circuit is transformed into the following Rank-1 Constraint System:
\begin{equation}
S_1 \cdot S_2 = 1
\end{equation}
Any valid assignment $<S_1,S_2>$ to this circuit enforces that $S_2$ is the multiplicative inverse of $S_1$, and, since there is no field element $S_2$ such that $0\cdot S_2=1$, it also handles the fact that the multiplicative inverse of $0$ is not defined in any field. 

Real-world compilers usually provide a gadget or a function to abstract over this circuit, and those functions compute the inverse $x^{-1}$ as part of their witness generation process. Programers then don't have to care about providing the inverse as auxiliary data to the circuit. In \lgname{PAPER}, we define the following inversion function that compiles to the previous circuit:
\begin{lstlisting}
fn INV(x : F, y : F) -> F {
  let x_inv : F ;
  constant c : F = 1 ;
  c <== MUL( x ,  y ) ) ;
  x_inv <== y ;
  return x_inv ;
}
\end{lstlisting}
As we see, this functions takes two inputs, the field value and its inverse. It therefore does not handle the computation of the inverse by itself. This is to keep \lgname{PAPER} as simple as possible. 

In the setup phase, we compile every occurrence of the $\mathtt{INV}$ function into an instance of the inversion circuit \ref{circ:inversion}, and edge labels are generated according to the rules from \ref{def:algebraic-circuit}.
\paragraph{The Division Constraint System}
\label{def:division_circuit} By definition, algebraic circuits only contain addition and multiplication gates, and it follows that there is no single gate for field division, despite the fact that division is a native operation in every field.

Implementing division as a circuit, we use the fact that division is multiplication with the multiplicative inverse. We therefore define division as a circuit using the inversion circuit and constraint system from the previous paragraph. Expensive inversion is computed outside of the circuit and then provided as circuit input. We get 
\begin{center}
\digraph[scale=0.4]{BTDIV}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 -> n6 [xlabel="S_1  "];
	n2 -> n4 [xlabel="S_2  "];
	n3 -> n6 [xlabel="S_3  "];
	n3 -> n4 [xlabel="S_3  "];
	n4 -> n5 [xlabel="1  "];
	n6 -> n7 [xlabel="S_4  "];
	n1 [shape=box, label="x"];
	n2 [shape=box, label="y"];
	n3 [shape=box, label="y^(-1)"];
	n4 [label="*"];	
	n5 [shape=box, label="1"];
	n6 [label="*"];	
	n7 [shape=box, label="DIV(x,y)"];	
}
\end{center} 
Using the method from \ref{sec:circuits_associated_R1CS}, we transform this circuit into the following Rank-1 Constraint System:
\begin{align*}
S_2 \cdot S_3 &= 1\\
S_1 \cdot S_3 &= S_4
\end{align*}
Any valid assignment $<S_1,S_2,S_3,S_4>$ to this circuit enforces $S_4$ to be the field division of $S_1$ by $S_2$. It handles the fact that division by $0$ is not defined, since there is no valid assignment in case $S_2=0$. 

In \lgname{PAPER}, we define the following division function that compiles to the previous circuit:
\begin{lstlisting}
fn DIV(x : F, y : F, y_inv : F) -> F {
  let DIV : F ;
  DIV <== MUL( x ,  INV( y, y_inv ) ) );
  return DIV
}
\end{lstlisting}
In the setup phase, we compile every occurrence of the binary $\mathtt{DIV}$ operator into an instance of the inversion circuit.
\begin{exercise} Let $\mathtt{F}$ be the field $\F_5$ of modular $5$ arithmetics from \examplename{} \ref{primfield_z_5}. Brain-compile the following \lgname{PAPER} statement into an algebraic circuit:
\begin{lstlisting}
statement STUPID_CIRC {F: F_5} {
  fn foo(in_1 : F, in_2 : F)->(out_1 : F, out_2 : F,){
    constant c_1 : F = 3 ;
    out_1<== ADD( MUL( c_1 , in_1 ) , in_1 ) ;
    out_2<== INV( c_1 , in_2 ) ;
  } ;
    
  fn main(in_1 : F, in_2 ; F)->(out_1 : F, out_2 : TYPE_2){
	constant (c_1,c_2) : (F,F) = (3,2) ;
    (out_1,out_2) <== foo(in_1, in_2) ;
  } ;
}
\end{lstlisting}
\end{exercise}
\begin{exercise} Consider the tiny-jubjub curve from \examplename{} \ref{TJJ13} and its associated circuit \ref{ex:3-fac-zk-circuit}. Write a statement in \lgname{PAPER} that brain-compiles the statement into a circuit equivalent to the one derived in \ref{ex:3-fac-zk-circuit}, assuming that curve point is the instance and every other assignment is a witness. 
\end{exercise}
\begin{exercise} Let $\mathtt{F}=\F_{13}$ be the modular $13$ prime field and $x\in\mathtt{F}$ some field element. Define a statement in \lgname{PAPER} such that given instance $x$ a field element $y\in\mathtt{F}$ is a witness for the statement if and only if $y$ is the square root of $x$.  

Brain-compile the statement into a circuit and derive its associated Rank-1 Constraint System. Consider the instance $x=9$ and compute a constructive proof for the statement. 
\begin{comment}
\begin{lstlisting}
statement KNOWLEDGE_OF_SQUARE_ROOT {F} {
  fn SQUARE(x : F)->(xx : F){
    xx<== MUL( x , x ) ;
  } ;
    
  fn main(pub x : F, y : F )->(){
    constant c_1 : F = 0 ;
    c_1 <==  SUB( x , SQUARE( y , y ) );
  } ;
}
\end{lstlisting}
\end{comment}
\end{exercise}
\begin{comment}
\paragraph{Modularity} Implementing bounded computation in algebraic circuits it is often necessary to deal with complex expressions of the field type. As we have seen in XXX\sme{add reference} and XXX\sme{add reference}, both algebraic circuits and R1CS have a modularity property, which enables a compiler to derive algebraic circuit implementations for arbitrary circuits. 
\begin{example}
To given an intuition of how real-world circuit compilers make use of the modularity property to synthesize complex circuits from high-level programs, we derive a circuit for the following \lgname{PAPER} code:
\begin{lstlisting}
def main<F_13>(private x : F, private y : F, private y^(-1) : F ) -> () {

	circuit:
		outc1 == DIV( ADD( , ) , , );
}
\end{lstlisting}
\end{example}
\begin{example} Consider the prime field $\F_{13}$. In this example, we want to derive an algebraic circuit and associated R1CS that enforces a pair $(x,y)\in \F_{13}^2$ to be the sum of two tiny-jubjub curve points $(x_1,y_1)$ and $(x_2,y_2)$. We assume that we already know that $(x_1,x_2)$ as well as $(x_2,y_2)$ are tiny-jubjub points, that is, we assume that they are the inputs to valid assignments of circuit XXX\sme{add reference}. 

To synthesize the associated circuit, we start with the twisted Edwards addition law XXX\sme{add reference} of the tiny-jubjub curve:
$$
(x,y) = \left(\frac{x_1y_2+y_1x_2}{1+8x_1y_1x_2y_2}, \frac{y_1y_2-3x_1x_2}{1-8x_1y_1x_2y_2} \right)
$$ 
To transform this expression into a circuit, we rewrite it in terms of the binary operators $ADD$, $SUB$, $MUL$, $DIV$ that represent the four fundamental field operations in $\F_{13}$. We get
\begin{align*}
(x,y) & = (\\
  & \scriptstyle DIV(ADD(MUL(x_1,y_2),MUL(y_1,x_2)),
         ADD(1,MUL(8,MUL(MUL(x_1,y_1),MUL(x_2,y_2))))), \\   
  & \scriptstyle DIV(ADD(MUL(y_1,y_2),MUL(MUL(3,x_1),x_2)),
         ADD(1,MUL(8,MUL(MUL(x_1,y_1),MUL(x_2,y_2)))))\\
  & )
\end{align*}
We then proceed inductively choosing circuits for the outer most operators, which in this case are two division circuits. We don't expand their inputs into circuits yet, but only represent the inputs symbolically. For better readability we use the symbols of the next operator only, because otherwise the circuit becomes unreadable. We get:
\begin{center}
\digraph[scale=0.4]{TEA}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	// x-value
	nx1 -> nx6 [xlabel="Ex_1  "];
	nx2 -> nx4 [xlabel="Ex_2  "];
	nx3 -> nx6 [xlabel="Ex_3  "];
	nx3 -> nx4 [xlabel="Ex_3  "];
	nx4 -> nx5 [xlabel="Ex_4  "];
	nx6 -> nx7 [xlabel="Ex_5  "];
	nx1 [shape=box, label="ADD(.,.)"];
	nx2 [shape=box, label="ADD(.,.)"];
	nx3 [shape=box, label="ADD(.,.)_INV"];
	nx4 [label="*"];	
	nx5 [shape=box, label="1"];
	nx6 [label="*"];	
	nx7 [shape=box, label="DIV(ADD(.,.),ADD(.,.))"];
	// y-value
	ny1 -> ny6 [xlabel="Ey_1  "];
	ny2 -> ny4 [xlabel="Ey_2  "];
	ny3 -> ny6 [xlabel="Ey_3  "];
	ny3 -> ny4 [xlabel="Ey_3  "];
	ny4 -> ny5 [xlabel="Ey_4  "];
	ny6 -> ny7 [xlabel="Ey_5  "];
	ny1 [shape=box, label="ADD(.,.)"];
	ny2 [shape=box, label="ADD(.,.)"];
	ny3 [shape=box, label="ADD(.,.)_INV"];
	ny4 [label="*"];	
	ny5 [shape=box, label="1"];
	ny6 [label="*"];	
	ny7 [shape=box, label="DIV(ADD(.,.),ADD(.,.))"];	
}
\end{center}

\end{example}
\end{comment}\sme{Is the comment group hidden on purpose?}

\subsubsection{The boolean Type} 
% implementations can be found here: https://github.com/filecoin-project/zexe/tree/master/snark-gadgets/src/bits
Booleans are a classical primitive type, implemented by virtually every higher programing language. It is therefore important to implement booleans in circuits. One of the most common ways to do this is by interpreting the additive and multiplicative neutral element $\{0,1\}\subset \F$ as the two boolean values such that $0$ represents $false$ and $1$ represents $true$. Boolean operators like $and$, $or$, or $xor$ are then expressible as algebraic circuits over $\F$. 

Representing booleans this way is convenient, because the elements $0$ and $1$ are defined in any field. The representation is therefore independent of the actual field in consideration. 

To fix boolean algebra notation, we write $0$ to represent $false$ and $1$ to represent $true$, and we write $\wedge$ to represent the boolean AND as well as $\vee$ to represent the boolean OR operator. The boolean NOT operator is written as $\lnot$. 
\paragraph{The boolean Constraint System}
\label{def:boolean_constraint} To represent booleans by the additive and multiplicative neutral elements of a field, a constraint is required to actually enforce variables of boolean type to be either $1$ or $0$. In fact, many of the following circuits that represent boolean functions are only correct under the assumption that their input variables are constrained to be either $0$ or $1$. Not constraining boolean variables is a common problem in circuit design.

In order to constrain an arbitrary field element $x\in \F$ to be $1$ or $0$, the key observation is that the equation $x \cdot (1-x) =0$ has only the two solutions $0$ and $1$ in any field. Implementing this equation as a circuit therefore generates the correct constraint:
\begin{center}
\digraph[scale=0.4]{BOOLCONS}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nCONS1 -> nCONS4 [xlabel="S_1"] ;
  nCONS1 -> nCONS6 [xlabel="S_1  "] ;
  nCONS2 -> nCONS5 ;
  nCONS3 -> nCONS4 ;
  nCONS4 -> nCONS5 ;
  nCONS5 -> nCONS6 ;
  nCONS6 -> nCONS7 [xlabel="0  "] ;
  nCONS1 [shape=box, label="x"] ;
  nCONS2 [shape=box, label="1"] ;
  nCONS3 [shape=box, label="-1"] ;
  nCONS4 [label="*"] ;
  nCONS5 [label="+"] ;
  nCONS6 [label="*"] ;
  nCONS7 [shape=box, label="0"] ;
}
\end{center}
Using the method from \ref{sec:circuits_associated_R1CS}, we transform this circuit into the following Rank-1 Constraint System:
$$
S_1 \cdot (1-S_1) = 0
$$
Any valid assignment $<S_1>$ to label of this circuit therefore enforces $S_1$ to be either the field element $0$ or $1$. 

Some real-world circuit compilers (like \texttt{ZOKRATES} or \texttt{BELLMAN}) are typed, while others (like \texttt{circom}) are not. However, all of them have their way of dealing with the binary constraint. In \lgname{PAPER}, we define the boolean type by its type\_function that compiles to the previous circuit:
\begin{lstlisting}
type_function BOOL(b : BOOL) -> F { 
	let x : F ;
	let const c1 : F = 0 ;
	let const c2 : F = 1 ;
	tet const c3 : F = -1 ;
    c1 <== MUL( b ,  ADD( c2 , MUL( b , c3) ) ) );
    x <== b ;
    return x ;
}
\end{lstlisting}
In the setup phase of a statement, we compile every occurrence of a variable of boolean type into an instance of its associated boolean circuit.
\paragraph{The AND operator constraint system} Given two field elements $b_1$ and $b_2$ from $\F$ that are constrained to represent boolean variables, we want to find a circuit that computes the logical \term{and} operator $AND(b_1,b_2)$ as well as its associated R1CS that enforces $b_1$, $b_2$, $AND(b_1,b_2)$ to satisfy the constraint system if and only if $b_1\; \wedge \; b_2 =AND(b_1,b_2)$ holds true. 

The key insight here is that, given three boolean constraint variables $b_1$, $b_2$ and $b_3$, the equation $b_1\cdot b_2 = b_3$ is satisfied in $\F$ if and only if the equation $b_1\; \wedge \; b_2 = b_3$ is satisfied in boolean algebra. The logical operator $\wedge$ is therefore implementable in $\F$ by field multiplication of its arguments and the following circuit computes the $\wedge$ operator in $\F$, assuming all inputs are restricted to be $0$ or $1$:
\begin{center}
\digraph[scale=0.4]{BOOLAND}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nAND1 -> nAND3 [xlabel="S_1  "] ;
  nAND2 -> nAND3 [xlabel="S_2"] ;
  nAND3 -> nAND4 [xlabel="S_3  "] ;

  nAND1 [shape=box, label="b_1"] ;
  nAND2 [shape=box, label="b_2"] ;
  nAND3 [label="*"] ;
  nAND4 [shape=box, label="AND(b_1,b_2)"] ;
}
\end{center}
The associated Rank-1 Constraint System can be deduced from the general process \ref{sec:circuits_associated_R1CS} and consists of the following constraint:
\begin{equation}
 S_1 \cdot S_2 = S_3
\end{equation}
Common circuit languages typically provide a gadget or a function to abstract over this circuit such that programers can use the $\wedge$ operator without caring about the associated circuit. In \lgname{PAPER}, we define the following function that compiles to the $\wedge$-operator's circuit:
\begin{lstlisting}
fn AND(b_1 : BOOL, b_2 : BOOL) -> BOOL{
  let AND : BOOL ; 
  AND <== MUL( b_1 ,  b_2) ;
  return AND ;
}
\end{lstlisting}
In the setup phase of a statement, we compile every occurrence of the $\mathtt{AND}$ function into an instance of its associated $\wedge$-operator's circuit.
\paragraph{The OR operator constraint system}
\label{def:boolean-or} Given two field elements $b_1$ and $b_2$ from $\F$ that are constrained to represent boolean variables, we want to find a circuit that computes the logical \term{or} operator $OR(b_1,b_2)$ as well as its associated R1CS that enforces $b_1$, $b_2$, $OR(b_1,b_2)$ to satisfy the constraint system if and only if $b_1\; \vee \; b_2 = OR(b_1,b_2)$ holds true. 

Assuming that three variables $b_1$, $b_2$ and $b_3$ are boolean constraint, the equation $b_1 + b_2 - b_1\cdot b_2 = b_3$ is satisfied in $\F$ if and only if the equation $b_1 \; \vee \; b_2 = b_3$ is satisfied in boolean algebra. The logical operator $\vee$ is therefore implementable in $\F$ by the following circuit, assuming all inputs are restricted to be $0$ or $1$:
\begin{center}
\digraph[scale=0.4]{BOOLOR}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  
  nOR1 [shape=box, label="b_1"] ;
  nOR2 [shape=box, label="b_2"] ;
  nOR3 [shape=box, label="-1"] ;
  nOR4 [label="*"] ;
  nOR5 [label="*"] ;
  nOR6 [label="+"] ;
  nOR7 [label="+"] ;
  nOR8 [shape="box", label="OR(b_1,b_2)"]
  
  nOR1 -> nOR4 [xlabel="S_1"] ;
  nOR1 -> nOR6 [xlabel="S_1"] ;
  nOR2 -> nOR4 [taillabel="S_2 "] ;
  nOR2 -> nOR6 [taillabel="S_2 "] ;
  nOR4 -> nOR5 [headlabel="  S_3"] ;
  nOR3 -> nOR5 ; 
  nOR5 -> nOR7 ;
  nOR6 -> nOR7 ;
  nOR7 -> nOR8 [xlabel="S_4 "] ;

}
\end{center}
The associated Rank-1 Constraint System can be deduced from the general process \ref{sec:circuits_associated_R1CS} and consists of the following constraints:

\begin{equation}\label{def:boolean-or_constraints}
\begin{tabular}{lcr}
$S_1 \cdot S_2$ & $=$ & $S_3$\\
$(S_1 + S_2 - S_3)\cdot 1$ &$=$ &$S_4$
\end{tabular}
\end{equation}

Common circuit languages typically provide a gadget or a function to abstract over this circuit such that programers can use the $\vee$ operator without caring about the associated circuit. In \lgname{PAPER}, we define the following function that compiles to the $\vee$-operator's circuit:
\begin{lstlisting}
fn OR(b_1 : BOOL, b_2 : BOOL) -> BOOL {
  let OR : BOOL ;
  let const c1 : F = -1 ;
  OR <== ADD(ADD(b_1,b_2),MUL(c1,MUL(b_1,b_2))) ;
  return OR ;
}
\end{lstlisting}
In the setup phase of a statement, we compile every occurrence of the $\mathtt{OR}$ function into an instance of its associated $\vee$-operator's circuit.
\begin{exercise} Let $\F$ be a finite field and let $b_1$ as well as $b_2$ two boolean constrained variables from $\F$. Show that the equation 
$OR(b_1,b_2) = 1 - (1 - b_1)\cdot (1 - b_2)$ holds true.

Use this equation to derive an algebraic circuit with ingoing variables $b_1$ and $b_2$ and outgoing variable $OR(b_1,b_2)$ such that $b_1$ and $b_2$ are boolean constrained and the circuit has a valid assignment, if and only if $OR(b_1,b_2) = b_1 \vee b_2$.  

Use the technique from \ref{sec:circuits_associated_R1CS} to transform this circuit into a Rank-1 Constraint System and find its full solution set. Define a \lgname{PAPER} function that brain-compiles into the circuit. 
\begin{comment}
\begin{center}
\digraph[scale=0.4]{BOOLOR}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nOR1 -> nOR5 [xlabel="S_1  "] ;
  nOR2 -> nOR7 [xlabel="S_2  "] ;
  nOR3 -> {nOR5, nOR7, nOR10} ;
  nOR4 -> {nOR6, nOR8, nOR11} ;
  nOR5 -> nOR6; 
  nOR6 -> nOR9 ;
  nOR7 -> nOR8 ;
  nOR8 -> nOR9 ;
  nOR9 -> nOR10 [xlabel="S_3  "] ;
  nOR10 -> nOR11 ;
  nOR11 -> nOR12 [xlabel="S_4  "] ;

  nOR1 [shape=box, label="b_1"] ;
  nOR2 [shape=box, label="b_2"] ;
  nOR3 [shape=box, label="-1"] ;
  nOR4 [shape=box, label="1"] ;
  nOR5 [label="*"] ;
  nOR6 [label="+"] ;
  nOR7 [label="*"] ;
  nOR8 [label="+"] ;
  nOR9 [label="*"] ;
  nOR10 [label="*"] ;
  nOR11 [label="+"] ;
  nOR12 [shape=box, label="OR(b_1,b_2)"] ;
}
\end{center}
The associated Rank-1 Constraint System can be deduced from the general process \ref{sec:circuits_associated_R1CS} and consists of the following constraints
\begin{align*}
 (1- S_1) \cdot (1-S_2) & = S_3\\
  (1-S_3)\cdot 1 &= S_4
\end{align*}
Common circuit languages typically provide a gadget or a function to abstract over this circuit such that programers can use the $\vee$ operator without caring about the associated circuit. In \lgname{PAPER}, we define the following function that compiles to the $\vee$-operator's circuit:
\begin{lstlisting}
fn OR(b_1 : BOOL, b_2 : BOOL) -> OR(b_1,b_2) : BOOL{
  l
  constant c1 = 1 ;
  constant c2 = -1 ;
  OR(b_1,b_2) <== ADD(c1,MUL(MUL(ADD(c1,MUL(b_1,c2)),ADD(c1,MUL(b_1,c2))),c2))  ;
}
\end{lstlisting}
In the setup phase of a statement, we compile every occurrence of the $\mathtt{OR}$ function into an instance of its associated $\vee$-operator's circuit.
\end{comment} 
\end{exercise}
\paragraph{The NOT operator constraint system} Given a field element $b$ from $\F$ that is constrained to represent a boolean variable, we want to find a circuit that computes the logical \term{NOT} operator $NOT(b)$ as well as its associated R1CS that enforces $b$, $NOT(b)$ to satisfy the constraint system if and only if $\lnot b = NOT(b)$ holds true. 

Assuming that two variables $b_1$ and $b_2$ are boolean constrained, the equation $(1-b_1) = b_2$ is satisfied in $\F$ if and only if the equation $\lnot b_1 = b_2$ is satisfied in boolean algebra. The logical operator $\lnot$ is therefore implementable in $\F$ by the following circuit, assuming all inputs are restricted to be $0$ or $1$:
\begin{center}
\digraph[scale=0.4]{BOOLNOT}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  nNOT1 -> nNOT4 [xlabel="S_1  "] ;
  nNOT2 -> nNOT4 ;
  nNOT3 -> nNOT5 ;
  nNOT4 -> nNOT5 ;
  nNOT5 -> nNOT6 [xlabel="S_2  "] ;

  nNOT1 [shape=box, label="b"] ;
  nNOT2 [shape=box, label="-1"] ;
  nNOT3 [shape=box, label="1"] ;
  nNOT4 [label="*"] ;
  nNOT5 [label="+"] ;
  nNOT6 [shape=box, label="NOT(b)"] ;
}
\end{center}
The associated Rank-1 Constraint System can be deduced from the general process \ref{sec:circuits_associated_R1CS} and consists of the following constraints
\begin{align*}
  (1-S_1)\cdot 1 &= S_2
\end{align*}
Common circuit languages typically provide a gadget or a function to abstract over this circuit such that programers can use the $\lnot$ operator without caring about the associated circuit. In \lgname{PAPER}, we define the following function that compiles to the $\lnot$-operator's circuit:
\begin{lstlisting}
fn NOT(b : BOOL -> BOOL{
  let NOT : BOOL ;
  let const c1 = 1 ;
  let const c2 = -1 ;
  NOT <== ADD( c1 , MUL( c2 , b) ) ;
  return NOT ;
}
\end{lstlisting}
In the setup phase of a statement, we compile every occurrence of the $\mathtt{NOT}$ function into an instance of its associated $\lnot$-operator's circuit.
\begin{exercise}
Let $\F$ be a finite field. Derive algebraic circuits and associated Rank-1 Constraint Systems for the following operators: NOR, XOR, NAND, EQU.
\end{exercise}
\paragraph{Modularity} As we have seen in chapter \ref{sec:statements}, both algebraic circuits and R1CS have a modularity property, and as we have seen in this section, all basic boolean functions are expressible in circuits. Combining those two properties shows that it is possible to express arbitrary boolean functions as algebraic circuits.

The expressiveness of algebraic circuits and therefore Rank-1 Constraint Systems is as general as the expressiveness of boolean circuits. An important implication is that the languages $L_{R1CS-SAT}$ and $L_{Circuit-SAT}$ as defined in \ref{r1cs-satisfiability} and \ref{circuit-satisfiability}, are as general as the famous language $L_{3-SAT}$, which is known to be $\mathcal{NP}$-complete. 
\begin{example} To give an example of how a compiler might construct complex boolean expressions in algebraic circuits from simple ones and how we derive their associated Rank-1 Constraint Systems, let's look at the following \lgname{PAPER} statement:
\begin{lstlisting}
statement BOOLEAN_STAT {F: F_p} {
  fn main(b_1:BOOL,b_2:BOOL,b_3:BOOL,b_4:BOOL )-> BOOL {
    let pub b_5 : BOOL ;
    b_5 <== AND( OR( b_1 , b_2) , AND( b_3 , NOT( b_4) ) ) ;
    return b_5 ;
  } ;
}
\end{lstlisting}
The code describes a circuit that takes four witness input variables $b_1$, $b_2$, $b_3$ and $b_4$ of boolean type and computes an instance variable output $b_5$ such that the following boolean expression holds true:
$$
\left( b_1 \vee b_2 \right) \wedge (b_3 \wedge \lnot b_4) = b_5
$$
During a setup-phase, a circuit compiler transforms this high-level language statement into a circuit and associated Rank-1 Constraint Systems and hence defines a  language $L_{BOOLEAN\_STAT}$. 

To see how this might be achieved, we use \lgname{PAPER} as an example to execute the setup-phase and compile \texttt{BOOLEAN\_STAT} into a circuit. Taking the definition of the boolean constraint \ref{def:boolean_constraint} as well as the definitions of the appropriate boolean operators into account, we get the following circuit:
\begin{center}
\digraph[scale=0.25]{BOOLCOMPLEX}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 1.0;
  rankdir=TB;

  subgraph clusterINPUT {
    nb1 [shape=box, label="b_1"] ;
    nb2 [shape=box, label="b_2"] ;    
    nb3 [shape=box, label="b_3"] ;
    nb4 [shape=box, label="b_4"] ;
    color=lightgray;
    label="inputs" ; 
  }
  
  subgraph clusterOUTPUT {
    nout1 [shape=box, label="AND( OR( b1 , b2 ) , AND( b3 , NOT( b4 ) )"]
    color=lightgray;
    label="outputs" ; 
  }
  
  subgraph clusterCONS  {
    subgraph clusterBCONS1 {
      nCONSB11 -> nCONSB14 [xlabel="S_1"] ;
      nCONSB11 -> nCONSB16 [xlabel="S_1"] ;
      nCONSB12 -> nCONSB15 ;
      nCONSB13 -> nCONSB14 ;
      nCONSB14 -> nCONSB15 ;
      nCONSB15 -> nCONSB16 ;
      nCONSB16 -> nCONSB17 [xlabel="w_5=0  "] ;
      nCONSB11 [shape=box, label="b", color=lightgray ] ;
      nCONSB12 [shape=box, label="1"] ;
      nCONSB13 [shape=box, label="-1"] ;
      nCONSB14 [label="*"] ;
      nCONSB15 [label="+"] ;
      nCONSB16 [label="*"] ;
      nCONSB17 [shape=box, label="0"] ;
      color=lightgray;
      label="b1 : BOOL" ;
    }
    
      subgraph clusterBCONS2 {
      nCONSB21 -> nCONSB24 [xlabel="S_1"] ;
      nCONSB21 -> nCONSB26 [xlabel="S_1"] ;
      nCONSB22 -> nCONSB25 ;
      nCONSB23 -> nCONSB24 ;
      nCONSB24 -> nCONSB25 ;
      nCONSB25 -> nCONSB26 ;
      nCONSB26 -> nCONSB27 [xlabel="W_6=0  "] ;
      nCONSB21 [shape=box, label="b", color=lightgray ] ;
      nCONSB22 [shape=box, label="1"] ;
      nCONSB23 [shape=box, label="-1"] ;
      nCONSB24 [label="*"] ;
      nCONSB25 [label="+"] ;
      nCONSB26 [label="*"] ;
      nCONSB27 [shape=box, label="0"] ;
      color=lightgray;
      label="b2 : BOOL" ;
    }
    
    subgraph clusterBCONS3 {
      nCONSB31 -> nCONSB34 [xlabel="S_1"] ;
      nCONSB31 -> nCONSB36 [xlabel="S_1"] ;
      nCONSB32 -> nCONSB35 ;
      nCONSB33 -> nCONSB34 ;
      nCONSB34 -> nCONSB35 ;
      nCONSB35 -> nCONSB36 ;
      nCONSB36 -> nCONSB37 [xlabel="W_7=0  "] ;
      nCONSB31 [shape=box, label="b", color=lightgray ] ;
      nCONSB32 [shape=box, label="1"] ;
      nCONSB33 [shape=box, label="-1"] ;
      nCONSB34 [label="*"] ;
      nCONSB35 [label="+"] ;
      nCONSB36 [label="*"] ;
      nCONSB37 [shape=box, label="0"] ;
      color=lightgray;
      label="b3 : BOOL" ;
    }
    
    subgraph clusterBCONS4 {
      nCONSB41 -> nCONSB44 [xlabel="S_1"] ;
      nCONSB41 -> nCONSB46 [xlabel="S_1"] ;
      nCONSB42 -> nCONSB45 ;
      nCONSB43 -> nCONSB44 ;
      nCONSB44 -> nCONSB45 ;
      nCONSB45 -> nCONSB46 ;
      nCONSB46 -> nCONSB47 [xlabel="W_8=0  "] ;
      nCONSB41 [shape=box, label="b", color=lightgray ] ;
      nCONSB42 [shape=box, label="1"] ;
      nCONSB43 [shape=box, label="-1"] ;
      nCONSB44 [label="*"] ;
      nCONSB45 [label="+"] ;
      nCONSB46 [label="*"] ;
      nCONSB47 [shape=box, label="0"] ;
      color=lightgray;
      label="b4 : BOOL" ;
    } 
    color = white ; 
  } 

  subgraph clusterCIRC{

    subgraph clusterORb1b2 {
      nOR1 [shape=box, label="b_1", color=lightgray] ;
      nOR2 [shape=box, label="b_2", color=lightgray] ;
      nOR3 [shape=box, label="-1"] ;
      nOR4 [label="*"] ;
      nOR5 [label="*"] ;
      nOR6 [label="+"] ;
      nOR7 [label="+"] ;
      nOR8 [shape="box", label="OR(b_1,b_2)", color=lightgray]
      
      nOR1 -> nOR4 [xlabel="S_1"] ;
      nOR1 -> nOR6 [xlabel="S_1"] ;
      nOR2 -> nOR4 [taillabel="S_2 "] ;
      nOR2 -> nOR6 [taillabel="S_2 "] ;
      nOR4 -> nOR5 [headlabel="  S_3"] ;
      nOR3 -> nOR5 ; 
      nOR5 -> nOR7 ;
      nOR6 -> nOR7 ;
      nOR7 -> nOR8 [xlabel="S_4 "] ;
      color=lightgray;
      label="fn OR" ;
    }

    subgraph clusterANDb3NOTb4 {
      nAND21 -> nAND23 [headlabel="  S_1"] ;
      nAND22 -> nAND23 [xlabel="S_2"] ;
      nAND23 -> nAND24 [xlabel="S_3 "] ;

      nAND21 [shape=box, label="b_1", color=lightgray ] ;
      nAND22 [shape=box, label="b_2", color=lightgray ] ;
      nAND23 [label="*"] ;
      nAND24 [shape=box, label="AND( b_1 , b_2 )", color=lightgray] ;
      color=lightgray;
      label="fn AND"
    }

    subgraph clusterNOTb4 {
      nNOT1 -> nNOT4 [xlabel="S_1 "] ;
      nNOT2 -> nNOT4 ;
      nNOT3 -> nNOT5 ;
      nNOT4 -> nNOT5 ;
      nNOT5 -> nNOT6 [headlabel="S_2 "] ;

      nNOT1 [shape=box, label="b", color=lightgray ] ;
      nNOT2 [shape=box, label="-1"] ;
      nNOT3 [shape=box, label="1"] ;
      nNOT4 [label="*"] ;
      nNOT5 [label="+"] ;
      nNOT6 [shape=box, label="NOT( b )", color=lightgray ] ;
      color=lightgray;
      label="fn NOT"
    }

    subgraph clusterAND1 {
      nAND1_1 -> nAND1_3 [xlabel="S_1"] ;
      nAND1_2 -> nAND1_3 [xlabel="S_2 "] ;
      nAND1_3 -> nAND1_4 [xlabel="S_3 "] ;
      nAND1_1 [shape=box, label="b_1", color=lightgray ] ;
      nAND1_2 [shape=box, label="b_2", color=lightgray] ;
      nAND1_3 [label="*"] ;
      nAND1_4 [shape=box, label="AND( b_1 , b_2 )", color=lightgray] ;
      color=lightgray;
      label="fn AND"
    }
    nNOT6 -> nAND22 [style=dashed, color=grey] ;
    nOR8 -> nAND1_1 [style=dashed, color=grey] ;
    nAND24 -> nAND1_2 [style=dashed, color=grey] ;
    
    color = white ; 
  }
  // outer circuit
    nb1 -> nCONSB11 [xlabel="W_1", style=dashed, color=grey] ;
    nCONSB11 -> nOR1 [style=dashed, color=grey] ;
    nb2 -> nCONSB21 [headlabel="W_2", style=dashed, color=grey] ;
    nCONSB21 -> nOR2 [style=dashed, color=grey] ;
    nb3 -> nCONSB31 [xlabel="W_3 ", style=dashed, color=grey] ;
    nCONSB31 -> nAND21 [style=dashed, color=grey] ;
    nb4 -> nCONSB41 [xlabel="W_4", style=dashed, color=grey] ;
    nCONSB41 -> nNOT1 [style=dashed, color=grey] ;
    nAND1_4 -> nout1 [xlabel="I_1"; style=dashed, color=grey] ;

}
\end{center}\sme{can we rotate this by $90^{\circ}$? Good question. IDK}
Simple optimization then collapses all box-nodes that are directly linked and all box nodes that represent the same constants. After relabeling the edges, the following circuit represents the circuit associated to the \texttt{BOOLEAN\_STAT} statement:
\begin{center}
\digraph[scale=0.5]{BOOLCOMPLEXOPTI}{
  forcelabels=true;
  center=true;
  splines=ortho;

  one -> nCONSb15 ;
  minusone -> nCONSb14 ;
  nCONSb14 -> nCONSb15 ;
  nCONSb15 -> nCONSb16 ;
  nCONSb16 -> zero [xlabel="W_5"] ;
  nCONSb14 [label="*"] ;
  nCONSb15 [label="+"] ;
  nCONSb16 [label="*"] ;

  one -> nCONSb25 ;
  minusone -> nCONSb24 ;
  nCONSb24 -> nCONSb25 ;
  nCONSb25 -> nCONSb26 ;
  nCONSb26 -> zero [headlabel="W_6 "] ;
  nCONSb24 [label="*"] ;
  nCONSb25 [label="+"] ;
  nCONSb26 [label="*"] ;

  one -> nCONSb35 ;
  minusone -> nCONSb34 ;
  nCONSb34 -> nCONSb35 ;
  nCONSb35 -> nCONSb36 ;
  nCONSb36 -> zero [taillabel="W_7"] ;
  nCONSb34 [label="*"] ;
  nCONSb35 [label="+"] ;
  nCONSb36 [label="*"] ;

  one -> nCONSb45 ;
  minusone -> nCONSb44 ;
  nCONSb44 -> nCONSb45 ;
  nCONSb45 -> nCONSb46 ;
  nCONSb46 -> zero [taillabel="W_8 "] ;
  nCONSb44 [label="*"] ;
  nCONSb45 [label="+"] ;
  nCONSb46 [label="*"] ;

  //minusone -> {nOR5, nOR7, nOR10} ;
  //one -> {nOR6, nOR8, nOR11} ;
  //nOR5 -> nOR6; 
  //nOR6 -> nOR9 ;
  //nOR7 -> nOR8 ;
  //nOR8 -> nOR9 ;
  //nOR9 -> nOR10 [headlabel="W_9  "] ;
  //nOR10 -> nOR11 ;
  //nOR5 [label="*"] ;
  //nOR6 [label="+"] ;
  //nOR7 [label="*"] ;
  //nOR8 [label="+"] ;
  //nOR9 [label="*"] ;
  //nOR10 [label="*"] ;
  //nOR11 [label="+"] ;
  
  // new 
  //nOR1 [shape=box, label="b_1"] ;
  //nOR2 [shape=box, label="b_2"] ;
  //nOR3 [shape=box, label="-1"] ;
  minusone -> nOR5 ;
  nOR4 [label="*"] ;
  nOR5 [label="*"] ;
  nOR6 [label="+"] ;
  nOR7 [label="+"] ;
  //nOR8 [shape="box", label="OR(b_1,b_2)"]
  
  //nOR1 -> nOR4 [xlabel="S_1"] ;
  //nOR1 -> nOR6 [xlabel="S_1"] ;
  //nOR2 -> nOR4 [taillabel="S_2 "] ;
  //nOR2 -> nOR6 [taillabel="S_2 "] ;
  nOR4 -> nOR5 [taillabel="W_9"] ;
  //nOR3 -> nOR5 ; 
  nOR5 -> nOR7 ;
  nOR6 -> nOR7 ;
  //nOR7 -> nOR8 [xlabel="S_4 "] ;

  nAND23 [label="*"] ;
  minusone -> nNOT4 ;
  one -> nNOT5 ;
  nNOT4 -> nNOT5 ;
  nNOT4 [label="*"] ;
  nNOT5 [label="+"] ;

  nOR7 -> nAND1_3; // here
  nAND23 -> nAND1_3 [xlabel="W_10"] ;
  nAND1_3 -> nAND1_4 [xlabel="I_1 "] ;
  nAND1_3 [label="*"] ;
  nAND1_4 [shape=box, label="AND( OR( b1 , b2 ) , AND( b3 , NOT( b4 ) )"] ;

  // outer circuit
    nNOT5 -> nAND23 ;
    b1 -> nOR4 [taillabel="  W_1"] ;
    b1 -> nOR6 [xlabel="W_1"] ;
    b1 -> nCONSb14 [headlabel="W_1 "] ;
    b1 -> nCONSb16 [headlabel="W_1     "] ;
    b2 -> nOR4 [taillabel=" W_2"] ;
    b2 -> nOR6  [headlabel=""] ;
    b2 -> nCONSb24 [headlabel=" W_2 "] ;
    b2 -> nCONSb26 [headlabel=" W_2 "] ;
    b3 -> nAND23 [xlabel=" W_3 "] ;
    b3 -> nCONSb34 [taillabel=" W_3"] ;
    b3 -> nCONSb36 [taillabel=""] ;
    b4 -> nNOT4 [headlabel=" W_4"] ;
    b4 -> nCONSb44 [headlabel=" W_4"] ;
    b4 -> nCONSb46 [headlabel="W_4"] ;
    b1 [shape=box, label="b1"] ;
    b2 [shape=box, label="b2"] ;
    b3 [shape=box, label="b3"] ;
    b4 [shape=box, label="b4"] ;
    minusone [shape=box, label="-1"] ;
    one [shape=box, label="1"] ;
    zero [shape=box, label="0"] ;
}
\end{center}
Given some instance variable $I_1$ from $\F_{13}$, a valid assignment to this circuit consists of witness variables $W_1$, $W_2$, $W_3$, $W_4$ from $\F_{13}$ such that the equation $I_1 = \left( W_1 \vee W_2 \right) \wedge (W_3 \wedge \lnot W_4)$ holds true. In addition, a valid assignment also has to contain witness variables $W_5$, $W_6$, $W_7$, $W_8$, $W_9$ and $W_{10}$, which can be derived from circuit execution. The variables $W_5$, $\ldots$, $W_8$ ensure that the first four witnesses are constrained to be either $0$ or $1$ but not any other field element, and the others enforce the boolean operations in the expression.  

To compute the associated R1CS, we can use the general method from \ref{sec:circuits_associated_R1CS} and look at every labeled outgoing edge not coming from a source node in the optimized circuit. We declare the edge going to the single output node as instance, and every other edge as witness. In this case we get:
\begin{align*}
W_5:\;\; & W_1 \cdot (1- W_1) = 0  & \text{boolean constraints}\\
W_6:\;\; & W_2 \cdot (1- W_2) = 0 \\
W_7:\;\; & W_3 \cdot (1- W_3) = 0 \\
W_8:\;\; & W_4 \cdot (1- w_4) = 0 \\
W_9:\;\; & W_1 \cdot W_2 = W_9 & \text{ first OR-operator constraint}\\
W_{10}:\;\; & W_3 \cdot (1-W_4) = W_{10} & \text{AND(.,NOT(.))-operator constraints}\\
I_1:\;\; & (W_1 + W_2 -W_9) \cdot W_{10} = I_1 & \text{AND-operator constraints}\\
\end{align*}
The reason why this R1CS only contains a single constraint for the multiplication gate in the OR-circuit, while the general definition \ref{def:boolean-or} requires two constraints, is that the second constraint in \ref{def:boolean-or_constraints} only appears because the final addition gate is connected to an output node. In this case, however, the final addition gate from the OR-circuit is enforced in the left factor of the $I_{1}$ constraint. Something similar holds true for the negation circuit. 

During a prover-phase, some public instance $I_5$ must be given. To compute a constructive proof for the statement of the associated languages with respect to instance $I_5$, a prover has to find four boolean values $W_1$, $W_2$, $W_3$ and $W_4$ such that 
$$
\left( W_1 \vee W_2 \right) \wedge (W_3 \wedge \lnot W_4) = I_5
$$ 
holds true. In our case neither the circuit nor the \lgname{PAPER} statement specifies how to find those values, and it is a problem that any prover has to solve outside of the circuit. This might or might not be true for other problems, too. In any case, once the prover found those values, they can execute the circuit to find a valid assignment. 

To give a concrete example, let $I_1=1$ and assume $W_1=1$, $W_2=0$, $W_3=1$ and $W_4=0$. Since 
$\left( 1 \vee 0 \right) \wedge (1 \wedge \lnot 0) = 1$, those values satisfy the problem and we can use them to execute the circuit. We get 
\begin{align*}
W_5 & = W_1 \cdot (1- W_1) = 0\\
W_6 & = W_2 \cdot (1- W_2) = 0 \\
W_7 & = W_3 \cdot (1- W_3) = 0 \\
W_8 & = W_4 \cdot (1- W_4) = 0 \\
W_9 & = W_1\cdot W_2 = 0\\
W_{10} & = W_3 \cdot (1-W_4) = 1\\
I_1 & = (W_1 + W_2 - W_9) \cdot W_{10} = 1
\end{align*}
A constructive proof of knowledge of a witness, for instance, $I_1=1$, is therefore given by the string $\pi=<W_5,W_6,W_7,W_8,W_9,W_{10}>=<0,0,0,0,0,1>$. 
\end{example}
\subsubsection{Arrays} The \texttt{array} type represents a fixed-size collection of elements of equal type, each selectable by one or more indices that can be computed at run time during program execution. 

Arrays are a classical type, implemented by many higher programing languages that compile to circuits or Rank-1 Constraint Systems. However, most high-level circuit languages support \term{static} arrays, i.e., arrays whose length is known at compile time only. 

The most common way to compile arrays to circuits is to transform any array of a given type $\texttt{t}$ and size $\texttt{N}$ into $\texttt{N}$ circuit variables of type $\texttt{t}$. Arrays are therefore \term{syntactic sugar}, with the purpose to make code easier for humans to read, and write. In \lgname{PAPER}, we define the following array type\_function:
\begin{lstlisting}
type_function <Name>: <Type>[N : unsigned] -> (Type,...) { 
  return (<Name>[0],...)
}
\end{lstlisting}
In the setup phase of a statement, we compile every occurrence of an array of size \texttt{N} that contains elements of type \texttt{Type} into \texttt{N} variables of type \texttt{Type}.
\begin{example} To give an intuition of how a real-world compiler might transform arrays into circuit variables, consider the following \lgname{PAPER} statement:
\begin{lstlisting}
statement ARRAY_TYPE {F: F_5} {
  fn main(x: F[2])-> F {
  	let constant c: F[2] = [2,4] ;
  	let out : F <== MUL(ADD(x[1],c[0]),ADD(x[0],c[1])) ;
  	return out ;
  } ;
}
\end{lstlisting}
During a setup phase, a circuit compiler might then replace any occurrence of the array type by a tuple of variables of the underlying type, and then use those variables in the circuit synthesis process instead. To see how this can be achieved, we use \lgname{PAPER} as an example. Abstracting over the sub-circuit of the computation, we get the following circuit:
\begin{center}
\digraph[scale=0.5]{SIMPLEARRAYCIRC}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;

    subgraph cluster_input {
      subgraph cluster_array1 {
          nx1 [shape= box, label="x[0]"] ;
          nx2 [shape= box, label="x[1]"] ;
          color=lightgray ;
          label="x[]" ;
      }

      subgraph cluster_array2 {
          nc1 [shape= box, label="c[0]"] ;
          nc2 [shape= box, label="c[1]"] ;
          color=lightgray ;
          label="c[]" ;
      }       
      color=lightgray ;
      label="inputs" ;
    }

    subgraph cluster_output {
        nout1 [shape= box, label="out"] ;
        color=lightgray ;
        label="outputs" ;
    }

    subgraph cluster_expression {
	    nexp1 [shape=box, label="MUL(ADD,ADD)"];
      color=lightgray ;
      label="fn MUL" ;
    }
   
    // subgraph connectors
    nx1 -> nexp1 [xlabel="Wx0"] ;  
    nx2 -> nexp1 [xlabel="Wx1"] ; 
    nc1 -> nexp1 [xlabel="Wc0"] ; 
    nc2 -> nexp1 [xlabel="Wc1"] ; 
    nexp1 -> nout1 [xlabel="Wout"] ;    
}
\end{center}
\end{example}
\subsubsection{The Unsigned Integer Type} Unsigned integers of size \texttt{N}, where \texttt{N} is usually a power of two, represent non-negative integers in the range $0\ldots 2^N-1$. They have a notion of addition, subtraction and multiplication, defined by modular $2^N$ arithmetics. If some \texttt{N} is given, we write \texttt{uN} for the associated type.

\paragraph{The uN Constraint System} Many high-level circuit languages define the various \texttt{uN} types as arrays of size \texttt{N}, where each element is of boolean type. This parallels their representation on common computer hardware and allows for efficient and straightforward definition of common operators, like the various shift operators, or the logical operators.

Assuming that some unsigned integer \texttt{N} is known at compile time in \lgname{PAPER}, we define the following \texttt{uN} type\_function, which casts a an unsigned integer into an array of boolean variables:
\begin{lstlisting}
type_function uN -> BOOL[N] { 
  let base2 : BOOL[N] ;
  base2[0] <== uN[0] ;
  base2[1] <== uN[1] ;
  ...
  base2[N] <== uN[N] ; 
  return base2 ;
}
\end{lstlisting}
To enfore an $N$-tuple of field elements $<b_0,\ldots,b_{N-1}>$ to represent an element of type \texttt{uN} we therefore need $N$ boolean constraints 
\begin{align*}
S_0 \cdot (1-S_0) & = 0\\
S_1 \cdot (1-S_1) & = 0\\
\cdots &\\
S_{N-1} \cdot (1-S_{N-1}) & = 0\\
\end{align*}
\begin{remark} Representing the \texttt{uN} type as boolean arrays is conceptually clean and works over generic base fields. However, representing unsigned integers in this way requires a lot of space as every bit is represented as a field element and if the base field is large, those field elements require considerable space in hardware.

It should be noted that, in some cases, there is another, more space- and Constraint System efficient approach for representing unsigned integers that can be used whenever the underlying base field is sufficiently large. To understand this, recall that addition and multiplication in a prime field $\F_p$ is equal to addition and multiplication of integers, as long as the sum or the product does exceed neither the modulus $p$ of the base field nor the modulus $2^N$ of the unsigned integer type. Under those limitations it is possible to represent the \texttt{uN} type inside the base-field type whenever $N$ is small enough. This however is not safe and care has to be taken to never overflow any of those moduli, or underflow $0$.
\end{remark}
\begin{example} To give an intuition of how a real-world compiler might transform unsigned integers into circuit variables, consider the following \lgname{PAPER} statement, which implement the classical ring-shift operator on the $u4$ type as a circuit:
\begin{lstlisting}
statement RING_SHIFT{F: F_p, N=4} {
  fn main(x: uN)-> uN {
  	let y : uN ;
  	y <== [x[1],x[2],x[3],x[0]] ;
  	return y ;
  } ;
}
\end{lstlisting}
During the setup-phase, a circuit compiler might then replace any occurrence of the \texttt{uN} type by \texttt{N} variables of \texttt{boolean} type. Using the definition of booleans, each of these variables is then transformed into the \texttt{field} type and a boolean constraint system. To see how this can be achieved, we use \lgname{PAPER} as an example and get the following circuit:

\begin{center}
\digraph[scale=0.25]{u4SHIFTER}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 1.0;

  subgraph clusteru41 {     
    subgraph clusterBOOL1 {
      nb11 [shape=box, label="x_0"] ;
      nb12 [shape=box, label="x_1"] ;    
      nb13 [shape=box, label="x_2"] ;
      nb14 [shape=box, label="x_3"] ;
      color=lightgray;
      label="BOOL[4]" ; 
    }
    color = lightgray ;
    label = "u4"
  }
  
  subgraph clusteru42 {     
    subgraph clusterBOOL2 {
      nb21 [shape=box, label="y_0"] ;
      nb22 [shape=box, label="y_1"] ;    
      nb23 [shape=box, label="y_2"] ;
      nb24 [shape=box, label="y_3"] ;
      color=lightgray;
      label="BOOL[4]" ; 
    }
    color = lightgray ;
    label = "u4"
  }  
  
  subgraph clusterCONS  {
    subgraph clusterBCONS1 {
      nCONSB11 -> nCONSB14 [xlabel="S_1"] ;
      nCONSB11 -> nCONSB16 [xlabel="S_1"] ;
      nCONSB11 -> nCONSB18 [style=dashed, color=lightgrey] ;
      nCONSB12 -> nCONSB15 ;
      nCONSB13 -> nCONSB14 ;
      nCONSB14 -> nCONSB15 ;
      nCONSB15 -> nCONSB16 ;
      nCONSB16 -> nCONSB17 [xlabel="S_2=0  "] ;
      nCONSB11 [shape=box, label="b:BOOL", color=lightgray ] ;
      nCONSB12 [shape=box, label="1"] ;
      nCONSB13 [shape=box, label="-1"] ;
      nCONSB14 [label="*"] ;
      nCONSB15 [label="+"] ;
      nCONSB16 [label="*"] ;
      subgraph clusterBCONS1out {
        nCONSB17 [shape=box, label="0"] ;
        nCONSB18 [shape=box, label="x:F", color=lightgrey] ;
        color = white ; 
      }
      color=lightgray;
      label="x1 : BOOL" ;
    }
    
    subgraph clusterBCONSB2 {
      nCONSB21 -> nCONSB24 [xlabel="S_1"] ;
      nCONSB21 -> nCONSB26 [xlabel="S_1"] ;
      nCONSB21 -> nCONSB28 [style=dashed, color=lightgrey] ;
      nCONSB22 -> nCONSB25 ;
      nCONSB23 -> nCONSB24 ;
      nCONSB24 -> nCONSB25 ;
      nCONSB25 -> nCONSB26 ;
      nCONSB26 -> nCONSB27 [xlabel="S_2=0  "] ;
      nCONSB21 [shape=box, label="b:BOOL", color=lightgray ] ;
      nCONSB22 [shape=box, label="1"] ;
      nCONSB23 [shape=box, label="-1"] ;
      nCONSB24 [label="*"] ;
      nCONSB25 [label="+"] ;
      nCONSB26 [label="*"] ;
      subgraph clusterBCONS1out {
        nCONSB27 [shape=box, label="0"] ;
        nCONSB28 [shape=box, label="x:F", color=lightgrey] ;
        color = white ; 
      }
      color=lightgray;
      label="x2 : BOOL" ;
    }
    
    subgraph clusterBCONSB3 {
      nCONSB31 -> nCONSB34 [xlabel="S_1"] ;
      nCONSB31 -> nCONSB36 [xlabel="S_1"] ;
      nCONSB31 -> nCONSB38 [style=dashed, color=lightgrey] ;
      nCONSB32 -> nCONSB35 ;
      nCONSB33 -> nCONSB34 ;
      nCONSB34 -> nCONSB35 ;
      nCONSB35 -> nCONSB36 ;
      nCONSB36 -> nCONSB37 [xlabel="S_2=0  "] ;
      nCONSB31 [shape=box, label="b:BOOL", color=lightgray ] ;
      nCONSB32 [shape=box, label="1"] ;
      nCONSB33 [shape=box, label="-1"] ;
      nCONSB34 [label="*"] ;
      nCONSB35 [label="+"] ;
      nCONSB36 [label="*"] ;
      subgraph clusterBCONS1out {
        nCONSB37 [shape=box, label="0"] ;
        nCONSB38 [shape=box, label="x:F", color=lightgrey] ;
        color = white ; 
      }
      color=lightgray;
      label="x3 : BOOL" ;
    }
    
    subgraph clusterBCONSB4 {
      nCONSB41 -> nCONSB44 [xlabel="S_1"] ;
      nCONSB41 -> nCONSB46 [xlabel="S_1"] ;
      nCONSB41 -> nCONSB48 [style=dashed, color=lightgrey] ;
      nCONSB42 -> nCONSB45 ;
      nCONSB43 -> nCONSB44 ;
      nCONSB44 -> nCONSB45 ;
      nCONSB45 -> nCONSB46 ;
      nCONSB46 -> nCONSB47 [xlabel="S_2=0  "] ;
      nCONSB41 [shape=box, label="b:BOOL", color=lightgray ] ;
      nCONSB42 [shape=box, label="1"] ;
      nCONSB43 [shape=box, label="-1"] ;
      nCONSB44 [label="*"] ;
      nCONSB45 [label="+"] ;
      nCONSB46 [label="*"] ;
      subgraph clusterBCONS1out {
        nCONSB47 [shape=box, label="0"] ;
        nCONSB48 [shape=box, label="x:F", color=lightgrey] ;
        color = white ; 
      }
      color=lightgray;
      label="x4 : BOOL" ;
    } 
    color = white ; 
  } 
  nb11 -> nCONSB11 ;
  nb12 -> nCONSB21 ;
  nb13 -> nCONSB31 ;
  nb14 -> nCONSB41 ;  
  nCONSB18 -> nb22;
  nCONSB28 -> nb23;
  nCONSB38 -> nb24;
  nCONSB48 -> nb21;
}
\end{center}
During the prover phase, the function \texttt{main} is called with an actual input of \texttt{u4} type, say \texttt{x=14}. The Prover then has to transform the decimal value $14$ into its $4$-bit binary representation $Bits(14)_2 = <0,1,1,1>$ outside of the circuit. Then the array of field values $x[4] = [0,1,1,1]$ is used as an input to the circuit. Since all $4$ field elements are either $0$ or $1$, the four boolean constraints are satisfied and the output is a ring shift of the input array of the four field elements given by $[1,1,1,0]$, which represents the \texttt{u4} element $7$. 
\end{example}
\paragraph{The Unigned Integer Operators} Since elements of \texttt{uN} type are represented as boolean arrays, shift operators are implemented in circuits simply by rewiring the boolean input variables to the output variables accordingly. 

Logical operators, like \texttt{AND}, \texttt{OR}, or \texttt{NOT} are defined on the \texttt{uN} type by invoking the appropriate boolean operators bitwise to every bit in the boolean array that represents the \texttt{uN} element.

Addition and multiplication can be represented similarly to how machines represent those operations. Addition can be implemented by first defining the \term{full adder} circuit and then combining $N$ of  these circuits into a circuit that adds two elements from the \texttt{uN} type.
\begin{comment}
To understand the algebraic circuit for the $1$-bit full, recall that we already defined circuits for boolean algebra in the previous section. Abstracting over those circuits, a full adder circuit can then be defined as:
\begin{center}
\digraph[scale=0.4]{ONEBFULLADD}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 2.0;
  
  subgraph clusterin {
    nADD01 [shape=box, label="bx_j"] ;
    nADD02 [shape=box, label="by_j"] ;
    nADD03 [shape=box, label="c_(j-1)"] ;
    color = white ;
  }
  
  subgraph clustermid {
    nADD04 [shape=box, label="XOR"] ;
    nADD05 [shape=box, label="XOR"] ;
    nADD06 [shape=box, label="AND"] ;
    nADD07 [shape=box, label="AND"] ;
    nADD08 [shape=box, label="OR"] ;
    
    nADD04 -> {nADD05, nADD06} ;
    nADD06 -> nADD08 ;
    nADD07 -> nADD08 ;
    
    color = white ;
  }
  
  subgraph clusterout {
    nADD09 [shape=box, label="bz_j"] ;
    nADD010 [shape=box, label="c_j"] ;
    color = white ;
  }
  
  nADD01 -> {nADD04, nADD07} ;
  nADD02 -> {nADD04, nADD07} ;
  nADD03 -> {nADD05, nADD06} ;
  nADD05 -> nADD09 ;
  nADD08 -> nADD010 ; 
}
\end{center}
In this circuit the output $bz_j$ is the result of the binary input $bx_j$ and $by_j$, where $bx_j$ is the $j$-th bit of the binary representation of the first summand and $by_j$ is the $j$-th bit of the binary representation of the second summand. The output $c_j$ is the carry bit of the addition and the input $c_{j-1}$ is is the carry bit which is supposed to be either $0$ for $j=0$ or the carry bit output of the previous full adder circuit. Abstracting the $1$-bit adder, we write:
\begin{center}
\digraph[scale=0.6]{BADDMETA}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  n1 [shape=box, label="FULLADD"] ;
  n2 [shape=none, label="bx_j"] ;
  n3 [shape=none, label="by_j"] ;
  n4 [shape=none, label="c_(j-1)"] ;
  n5 [shape=none, label="bz_j"] ;
  n6 [shape=none, label="c_j"] ;
  n2 -> n1 ;
  n3 -> n1 ;
  n4 -> n1 ;
  n1 -> {n5, n6} ;
}
\end{center}
With a circuit definition of the $1$-bit full adder at hand, addition of two uIntN type elements can then be defined as
\begin{center}
\digraph[scale=0.4]{UINTADD}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  
  subgraph clusterin0 {
    nADD01 [shape=box, label="FULLADD"] ;
    nADD02 [shape=none, label="bx_0"] ;
    nADD03 [shape=none, label="by_0"] ;
    nADD05 [shape=none, label="bz_0"] ;
    nADD02 -> nADD01 ;
    nADD03 -> nADD01 ;
    nADD01 -> nADD05 ;
    color = white ;
  }
  
  subgraph clusterin1 {
    nADD11 [shape=box, label="FULLADD"] ;
    nADD12 [shape=none, label="bx_1"] ;
    nADD13 [shape=none, label="by_1"] ;
    //nADD14 [shape=none, label="c_0"] ;
    nADD15 [shape=none, label="bz_1"] ;
    nADD12 -> nADD11 ;
    nADD13 -> nADD11 ;
    //nADD14 -> nADD11 ;
    nADD11 -> nADD15 ;
    color = white ;
  }

  subgraph clusterin2 {
    nADD21 [shape=box, label="FULLADD", color=lightgray] ;
    nADD22 [shape=none, label="bx_j", color=lightgray] ;
    nADD23 [shape=none, label="by_j", color=lightgray] ;
    //nADD24 [shape=none, label="c_(j-1)", color=lightgray] ;
    nADD25 [shape=none, label="bz_j", color=lightgray] ;
    nADD22 -> nADD21 [color=lightgray];
    nADD23 -> nADD21 [color=lightgray];
    //nADD24 -> nADD21 ;
    nADD21 -> nADD25 [color=lightgray] ;
    color = white ;
  }
  
  subgraph clusterinN {
    nADDN1 [shape=box, label="FULLADD"] ;
    nADDN2 [shape=none, label="bx_(N-1)"] ;
    nADDN3 [shape=none, label="by_(N-1)"] ;
    //nADDN4 [shape=none, label="c_(N-2)"] ;
    nADDN5 [shape=none, label="bz_(N-1)"] ;
    nADDN2 -> nADDN1 ;
    nADDN3 -> nADDN1 ;
    //nADDN4 -> nADDN1 ;
    nADDN1 -> nADDN5
    color = white ;
  }
  
  nADD04 [shape=none, label="0"] ;
  nADD04 -> nADD01 ;
  nADD01 -> nADD11 ;
  nADD11 -> nADD21 [style=dashed, color=lightgrey] ;
  nADD21 -> nADDN1  [style=dashed, color=lightgrey] ;
  nADDN6 [shape=none, label="c_out"] ;
  nADDN1 -> nADDN6 ;
  
}
\end{center}
Depending on how the output carry bit is handled we get different definition of addition in this type. One way would be to enforce it to be zero. This way addition in the circuit is only possible if the sum does not exceed $2^N-1$. On the other hand if the carry bit is unconstraint, then the resulting addition is equivalent to modulo $2^N$ arithmetics. Good  compilers should therefore always describe explicitly how exactly their implementation of the uintN type behaves such that users don't build their system on false assumptions. 

The associated constraint system consists of XXX\sme{add reference} constraints, including the boolean constraints of the representing bits
\paragraph{The boolean Operators} In implementations it is often necessary to execute boolean operations like $ans$, $or$, or $xor$ on elements of the uInt type. Fortunately this easily done by simply applying those operators to every bit separately as shown in XXX\sme{add reference}.  
\end{comment}
% =====================================
\begin{exercise}
Let \texttt{F}$=\F_{13}$ and \texttt{N=4} be fixed and let $x$ be of $uN$ type. Define circuits and associated R1CS for the left and right bit-shift operators $x<<2$ as well as $x>>2$. Execute the associated circuit for $x : u4 = 11$ and generate a constructive proof for $R1CS$ satisfyability.
\end{exercise}
\begin{exercise}
Let \texttt{F}$=\F_{13}$ and \texttt{N=2} be fixed. Define a circuit and associated R1CS for the addition operator $\mathtt{ADD}: uN \times uN \to uN$. Execute the associated circuit to compute $\mathtt{ADD}(2,7)$ for $2,7\in uN$.
\end{exercise}
\begin{exercise} Execute the setup phase for the following \lgname{PAPER} code (That is brain compile the code into a circuit and derive the associated R1CS). 
\begin{lstlisting}
statement MASK_MERGE {F:F_5, N=4} {
  fn main(pub a : uN, pub b : uN) -> uN {
    let constant mask : uN = 10 ;
    let r : uN ;
    r <== XOR(a,AND(XOR(a,b),mask)) ;
    return r ;
  }
}
\end{lstlisting}
Let $L_{mask\_merge}$ be the language defined by the circuit. Provide a constructive knowledge proof in $L_{mask\_merge}$ for the instance $I=(I_a, I_b) = (14, 7)$.
\end{exercise}
\subsection{Control Flow} Most programming languages of the imperative of functional style have some notion of basic control structures to direct the order in which instructions are evaluated. Contemporary circuit compilers usually provide a single thread of execution and provide basic flow constructs that implement control flow in circuits. In this part we look at some basic control flow constructions and their implementation in circuits.
\subsubsection{The Conditional Assignment} Writing high-level code that compiles to circuits, it is often necessary to have a way for conditional assignment of values or computational output to variables. One way to realize this in many programming languages is in terms of the conditional ternary assignment operator $?:$ that branches the control flow of a program according to some condition and then assigns the output of the computed branch to some variable: 
\begin{lstlisting}
variable = condition ? value_if_true : value_if_false  
\end{lstlisting}
In this description, \texttt{condition} is a boolean expression and \texttt{value\_if\_true} as well as \texttt{value\_if\_false} are expressions that evaluate to the same type as \texttt{variable}.

In programming languages like Rust, another way to write the conditional assignment operator that is more familiar to many programmers is given by 
\begin{lstlisting}
variable = if condition then { 
  value_if_true 
} else { 
  value_if_false 
} 
\end{lstlisting}
In most programing languages, it is a key property of the ternary assignment operator that the expression \texttt{value\_if\_true} is only evaluated if \texttt{condition} evaluates to true and the expression \texttt{value\_if\_false} is only evaluated if \texttt{condition} evaluates to false. In fact, computer programs would turn out to be very inefficient if the ternary operator would evaluate both expressions regardless of the value of \texttt{condition}.

A simple way to implement conditional assignment operator as a circuit can be achieved if the requirement that only one branch of the conditional operator is executed is dropped. To see that, let $b$, $c$ and $d$ be field elements such that $b$ is boolean constrained. In this case, the following equation enforces a field element $x$ to be the result of the conditional assignment operator: 
\begin{equation}
\label{def:conditional_operator_equation}
x = b\cdot c + (1-b)\cdot d
\end{equation}
Expressing this equation in terms of the addition and multiplication operators from \ref{def:base_field_type}, we can flatten \ref{def:conditional_operator_equation} into the following algebraic circuit:
\begin{center}
\digraph[scale=0.4]{CONDASSIGN}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;

  n1 [shape=box, label="b"]
  n2 [shape=box, label="c"]
  n3 [shape=box, label="d"]
  n4 [shape=box, label="b ? c : d"]
  n5 [shape=box, label="-1"]
  n6 [shape=box, label="1"]
  n7 [label="*"]
  n8 [label="*"]
  n9 [label="*"]
  n10 [label="+"]
  n11 [label="+"]
 
  n1 -> n7 [taillabel= "S_1  "] ;
  n1 -> n8 [taillabel= "S_1 "] ;
  n2 -> n7 [xlabel= "S_2"] ;
  n3 -> n9 [xlabel= "S_4"] ;
  n5 -> n8 ;
  n6 -> n10 ;
  n7 -> n11 [xlabel= "S_3  "] ;
  n8 -> n10 ;
  n9 -> n11 [xlabel= "S_5"] ;
  n10 -> n9 ;
  n11 -> n4 [xlabel= "S_6  "] ;
}
\end{center}
Note that, in order to compute a valid assignment to this circuit, both $S_2$ as well as $S_4$ are necessary. If the inputs to the nodes $c$ and $d$ are circuits themself, both circuits need valid assignments and therefore have to be executed. As a consequence, this implementation of the conditional assignment operator has to execute all branches of all circuits, which is very different from the execution of common computer programs and contributes to the increased computational effort any prover has to invest, in contrast to the execution in other programing models. 

We can use the general technique from \ref{sec:circuits_associated_R1CS} to derive the associated Rank-1 Constraint System of the conditional assignment operator. We get the following:
\begin{align*}
S_1 \cdot S_2 & = S_3 \\
(1 - S_1) \cdot S_4 & = S_5 \\
(S_3 + S_5)\cdot 1 &= S_6
\end{align*}
\begin{example} To give an intuition of how a real-world circuit compiler might transform any high-level description of the conditional assignment operator into a circuit, consider the following \lgname{PAPER} code:
\begin{lstlisting}
statement CONDITIONAL_OP {F:F_p} {
  fn main(x : F, y : F, b : BOOL) -> F {
    let z : F 
    z <== if b then { 
      ADD(x,y) 
    } else { 
      MUL(x,y) 
    } ;
    return z ; 
  }
}
\end{lstlisting}
Brain-compiling this code into a circuit, we first draw box nodes for all input and output variables, and then transform the boolean type into the field type together with its associated constraint. Then we evaluate the assignments to the output variables. Since the conditional assignment operator is the top level function, we draw its circuit and then draw the circuits for both conditional expressions. We get the following:
\begin{center}
\digraph[scale=0.4]{CONDITIONALOP}{
  forcelabels=true;
  center=true;
  splines=ortho;
  nodesep= 1.0;

  subgraph clusterinput { 
    nb11 [shape=box, label="x:F"] ;
    nb12 [shape=box, label="y:F"] ;    
    nb13 [shape=box, label="b:BOOL"] ;
    color = lightgray ;
    label = "input"
  }
  
  subgraph clusterout {
    nb21 [shape=box, label="z"] ;
    color=lightgray;
    label="output" ; 
  }  
  
    subgraph clusterBCONS1 {
      nCONSB11 -> nCONSB14 [xlabel="S_1"] ;
      nCONSB11 -> nCONSB16 [xlabel="S_1"] ;
      nCONSB11 -> nCONSB18 [style=dashed, color=lightgrey] ;
      nCONSB12 -> nCONSB15 ;
      nCONSB13 -> nCONSB14 ;
      nCONSB14 -> nCONSB15 ;
      nCONSB15 -> nCONSB16 ;
      nCONSB16 -> nCONSB17 [xlabel="S_2=0  "] ;
      nCONSB11 [shape=box, label="b:BOOL", color=lightgray ] ;
      nCONSB12 [shape=box, label="1"] ;
      nCONSB13 [shape=box, label="-1"] ;
      nCONSB14 [label="*"] ;
      nCONSB15 [label="+"] ;
      nCONSB16 [label="*"] ;
      subgraph clusterBCONS1out {
        nCONSB17 [shape=box, label="0"] ;
        nCONSB18 [shape=box, label="x:F", color=lightgrey] ;
        color = white ; 
      }
      color=lightgray;
      label="x1 : BOOL" ;
    } 
    
    subgraph clusterconditional{
      nCONDI1 [shape=box, label="b", color=lightgrey]
      nCONDI2 [shape=box, label="c", color=lightgrey]
      nCONDI3 [shape=box, label="d", color=lightgrey]
      nCONDI4 [shape=box, label="b ? c : d", color=lightgrey]
      nCONDI5 [shape=box, label="-1"]
      nCONDI6 [shape=box, label="1"]
      nCONDI7 [label="*"]
      nCONDI8 [label="*"]
      nCONDI9 [label="*"]
      nCONDI10 [label="+"]
      nCONDI11 [label="+"]
     
      nCONDI1 -> nCONDI7 [taillabel= "S_1  "] ;
      nCONDI1 -> nCONDI8 [taillabel= "S_1 "] ;
      nCONDI2 -> nCONDI7 [xlabel= "S_2"] ;
      nCONDI3 -> nCONDI9 [xlabel= "S_4"] ;
      nCONDI5 -> nCONDI8 ;
      nCONDI6 -> nCONDI10 ;
      nCONDI7 -> nCONDI11 [xlabel= "S_3  "] ;
      nCONDI8 -> nCONDI10 ;
      nCONDI9 -> nCONDI11 [xlabel= "S_5"] ;
      nCONDI10 -> nCONDI9 ;
      nCONDI11 -> nCONDI4 [xlabel= "S_6  "] ;
      
      color=lightgray;
      label="b ? c : d" ;
    }
    
    subgraph clusterADD {
      nADD1 [shape=box, label="x", color=lightgrey] ;
      nADD2 [shape=box, label="y", color=lightgrey] ;
      nADD3 [label="+"] ;
      nADD4 [shape=box, label="ADD(x,y)", color=lightgrey] ;
      
      nADD1 -> nADD3 ;
      nADD2 -> nADD3 ;
      nADD3 -> nADD4 ;
      
      color=lightgray;
      label="ADD" ;
    }
    
    subgraph clusterMUL {
      nMUL1 [shape=box, label="x", color=lightgrey] ;
      nMUL2 [shape=box, label="y", color=lightgrey] ;
      nMUL3 [label="+"] ;
      nMUL4 [shape=box, label="MUL(x,y)", color=lightgrey] ;
      
      nMUL1 -> nMUL3 ;
      nMUL2 -> nMUL3 ;
      nMUL3 -> nMUL4 ;
      
      color=lightgray;
      label="MUL" ;
    }
    nb11 -> {nMUL1, nADD1} [style=dashed, color=lightgrey] ; 
    nb12 -> {nMUL2, nADD2} [style=dashed, color=lightgrey] ; 
    nb13 -> nCONSB11 [style=dashed, color=lightgrey] ;  
    nCONSB18 -> nCONDI1 [style=dashed, color=lightgrey] ; 
    nADD4 -> nCONDI2 [style=dashed, color=lightgrey] ; 
    nMUL4 -> nCONDI3 [style=dashed, color=lightgrey] ; 
    nCONDI4 -> nb21 [style=dashed, color=lightgrey] ; 
  // outer circuit
}
\end{center}
\end{example}

% NOTE: ZK-Podcast with Alex zdemir for the proper branching thing in version 2 of the book.

\subsubsection{Loops} In many programming languages, various loop control structures are defined that allow developers to execute expressions with a specified number of repetitions. In particular, it is often possible to implement unbounded loops like the loop structure give below:
\begin{lstlisting}
  while true do { }
\end{lstlisting}
In addition it is often possible to implement loop structures, where the number of execution steps in the loop depends on execution inputs or intermediate computational steps and is therefore unknown at compile time: 
\begin{lstlisting}
  x = 0.5
  while x != 0 do { 
    x = 4*x*(1-x) 
  }
\end{lstlisting}

In contrast to this, algebraic circuits and Rank-1 Constraint Systems are not general enough to express arbitrary computation, but bounded computation only. As a consequence,  it is not possible to implement unbounded loops, or loops with bounds that are unknown at compile time in those models. This can be easily seen since circuits are acyclic by definition, and implementing an unbounded loop as an acyclic graph requires a circuits of unbounded size.  However, circuits are general enough to express bounded loops, where the upper bound on its execution is known at compile time. Those loop can be implemented in circuits by enrolling the loop. 

As a consequence, any programing language that compiles to algebraic circuits can only provide loop structures where the bound is a constant known at compile time. This implies that loops cannot depend on execution inputs, but on compile time parameters only.  
\begin{example} To give an intuition of how a real-world circuit compiler might transform any high-level description of a bounded \texttt{for} loop into a circuit, consider the following \lgname{PAPER} code:
\begin{lstlisting}
statement FOR_LOOP {F:F_p, N: unsigned = 4} {
  fn main(fac : F[N]) -> F {
  	let prod[N] : F ;
  	prod[0] <== fac[0] ;
    for unsigned i in 1..N do [{
      prod[i] <== MUL(fac[i], prod[i-1]) ; 
    }
    return prod[N] ;
  }
}
\end{lstlisting}
Note that, in a program like this, the loop counter \texttt{i} has no expression in the derived circuit. It is a high level parameter that tells the compiler how to unroll the loop.

Brain-compiling this code into a circuit, we first draw box nodes for all input and output variables, noting that the loop counter is not represented in the circuit. Since all variables are of \texttt{field} type, we don't have to compile any type constraints. Then we evaluate the assignments to the output variables by unrolling the loop into $3$ individual assignment operators. We get:
\begin{center}
\digraph[scale=0.3]{SIMPLELOOP}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  rankdir="LR" ;
  
  subgraph clusterINPUT {
    nIN1 [shape=box, label="fac[0]"] ;
    nIN2 [shape=box, label="fac[1]"] ;
    nIN3 [shape=box, label="fac[2]"] ;
    nIN4 [shape=box, label="fac[3]"] ;
    color = lightgray ;
    label = "input" ;
  }
  
  subgraph clusterOUTPUT {
    nOUT4 [shape=box, label="prod[3]"] ;    
    color = lightgray ;
    label = "output" ;
  }
  
  subgraph clusterMUL1 {
    nMUL11 [shape=box, label="x", color=lightgray] ;
    nMUL12 [shape=box, label="y", color=lightgray] ;
    nMUL13 [label="*"] ;
    nMUL14 [shape=box, label="MUL(x,y)", color=lightgray] ;
    nMUL11 -> nMUL13 ;
    nMUL12 -> nMUL13 ;
    nMUL13 -> nMUL14 ;
    color = lightgray ;
    label="MUL" ;
  }
  
    subgraph clusterMUL2 {
    nMUL21 [shape=box, label="x", color=lightgray] ;
    nMUL22 [shape=box, label="y", color=lightgray] ;
    nMUL23 [label="*"] ;
    nMUL24 [shape=box, label="MUL(x,y)", color=lightgray] ;
    nMUL21 -> nMUL23 ;
    nMUL22 -> nMUL23 ;
    nMUL23 -> nMUL24 ;
    color = lightgray ;
    label="MUL" ;
  }
  
    subgraph clusterMUL3 {
    nMUL31 [shape=box, label="x", color=lightgray] ;
    nMUL32 [shape=box, label="y", color=lightgray] ;
    nMUL33 [label="*"] ;
    nMUL34 [shape=box, label="MUL(x,y)", color=lightgray] ;
    nMUL31 -> nMUL33 ;
    nMUL32 -> nMUL33 ;
    nMUL33 -> nMUL34 ;
    color = lightgray ;
    label="MUL" ;
  }

  nOUT1 [shape=box, label="prod[0]", color=lightgrey] ;
  nOUT2 [shape=box, label="prod[1]", color=lightgrey] ;
  nOUT3 [shape=box, label="prod[2]", color=lightgrey] ;
  
  nIN1 -> nOUT1 [style=dashed, color=lightgrey] ;
  
  nOUT1 -> nMUL12 [style=dashed, color=lightgrey] ;
  nIN2 -> nMUL11 [style=dashed, color=lightgrey] ;
  nMUL14 -> nOUT2 [style=dashed, color=lightgrey] ;
 
  nOUT2 -> nMUL22 [style=dashed, color=lightgrey] ;
  nIN3 -> nMUL21 [style=dashed, color=lightgrey] ;
  nMUL24 -> nOUT3 [style=dashed, color=lightgrey] ; 
  
  nOUT3 -> nMUL32 [style=dashed, color=lightgrey] ;
  nIN4 -> nMUL31 [style=dashed, color=lightgrey] ;
  nMUL34 -> nOUT4 [style=dashed, color=lightgrey] ;  
  
}
\end{center}
\end{example}
\subsection{Binary Field Representations} In applications, it is often necessary to enforce a binary representation of elements from the \texttt{field} type. To derive an appropriate circuit over a prime field $\F_p$, let $m=|p|_2$ be the smallest number of bits necessary to represent the prime modulus $p$. Then a bitstring $<b_0,\ldots,b_{m-1}>\in \{0,1\}^m$ is a binary representation of a field element $x\in\F_p$, if and only if
\begin{equation}
\label{def:binary_field_rep}
x = b_0\cdot 2^0 + b_1\cdot 2^1 + \ldots + b_m\cdot 2^{m-1}
\end{equation}
In this expression, addition and exponentiation is considered to be executed in $\F_p$, which is well defined since all terms $2^j$ for $0\leq j < m$ are elements of $\F_p$. Note, however, that in contrast to the binary representation of unsigned integers $n\in\N$, this representation is not unique in general, since the modular $p$ equivalence class might contain more than one binary representative. 

Considering that the underlying prime field is fixed and the most significant bit of the prime modulus is $m$, the following circuit flattens equation \ref{def:binary_field_rep}, assuming all inputs $b_1$, $\ldots$, $b_m$ are of boolean type.
\begin{center}
\digraph[scale=0.3]{BINARYREP}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;

  subgraph cluster0 {
    n1 [shape=box, label="b_0"] ;
    n2 [shape=box, label="2^0"] ;
    n3 [label="*"] ;

    n1 -> n3 [xlabel="S_0"] ;
    n2 -> n3 ;
    color=white ;
  }

  subgraph cluster1 {
    n4 [shape=box, label="b_1"] ;
    n5 [shape=box, label="2^1"] ;
    n6 [label="*"] ;

    n4 -> n6 [xlabel="S_1  "] ;
    n5 -> n6 ;
    color=white ;
  }

  subgraph cluster2 {
    n7 [shape=box, label="b_2"] ;
    n8 [shape=box, label="2^2"] ;
    n9 [label="*"] ;

    n7 -> n9 [xlabel="S_2  "] ;
    n8 -> n9 ;
    color=white ;
  }

  subgraph cluster3 {
    n10 [shape=box, label="...", color=lightgrey] ;
    color=white ;
  }

  subgraph cluster4 {
    n11 [shape=box, label="b_(m-1)"] ;
    n12 [shape=box, label="2^(m-1)"] ;
    n13 [label="*"] ;

    n11 -> n13 [xlabel="S_(m-1)  "] ;
    n12 -> n13 ;
    color=white ;
  }

  subgraph cluster5 {
    n18 [shape=box, label="x"] ;
    n19 [shape=box, label="-1"] ;
    n20 [label="*"] ;

    n18 -> n20  [xlabel="S_m"] ;
    n19 -> n20 ;
    color=white ;
  }

  n14 [label="+"] ;
  n15 [label="+"] ;
  n16 [label="+", color=lightgrey] ;
  n17 [label="+"] ;
  n21 [label="+"] ;
  n22 [shape=0, label="0"] ;
  n3 -> n14 ;
  n6 -> n14 ; 
  n14 -> n15 ;
  n9 -> n15 ;
  n10 -> n16 [style=dashed, color=lightgrey] ;
  n15 -> n16 [style=dashed, color=lightgrey] ;
  n13 -> n17 ;
  n16 -> n17 [style=dashed, color=lightgrey] ;
  n20 -> n21 ;
  n17 -> n21 ;
  n21 -> n22  [xlabel="W_1=0  "] ;
}
\end{center}
Applying the general transformation rule \ref{sec:circuits_associated_R1CS} to compute the associated Rank-1 Constraint Systems, we see that we actually only need a single constraint to enforce some binary representation of any field element. We get 
$$
(S_0\cdot 2^0 + S_1\cdot 2^1 + \ldots + S_{m-1}\cdot 2^{m-1} -S_m)\cdot 1 = 0
$$
Given an array \texttt{BOOL[N]} of \texttt{N} boolean constrained field elements and another field element $x$, the circuit enforces \texttt{BOOL[N]} to be one of the binary representations of $x$. If \texttt{BOOL[N]} is not a binary representation of $x$, no valid assignment and hence no solution to the associated R1CS can exists. 
\begin{example} Consider the prime field $\F_{13}$. To compute binary representations of elements from that field, we start with the binary representation of the prime modulus $13$, which is $Bits(13) = <1,0,1,1>$ since $13= 1\cdot 2^0 + 0\cdot 2^1 + 1\cdot 2^2 + 1\cdot 2^3$. So $m=4$ and we need up to $4$ bits to represent any element $x\in\F_{13}$.

To see that binary representations are not unique in general, consider the element $2\in \F_{13}$. It has the following two $4$-bit, binary representations $Bits(2)=<0,1,0,0>$ and $Bits(2)=<1,1,1,1>$, since in $\F_{13}$ we have
$$
2 = \begin{cases}
0\cdot 2^0 + 1\cdot 2^1 + 0\cdot 2^2 + 0\cdot 2^3\\
1\cdot 2^0 + 1\cdot 2^1 + 1\cdot 2^2 + 1\cdot 2^3
\end{cases}
$$
This is because the unsigned integers $2$ and $15$ are both in the modular $13$ remainder class of $2$ and hence are both representatives of $2$ in $\F_{13}$.

To see how circuit the associated circuit works, we want to enforce the binary representation of $7\in \F_{13}$. Since $m=4$ we have to enforce a $4$-bit representation for $7$, which is $<1,1,1,0>$, since $7= 1\cdot 2^0 + 1\cdot 2^1 + 1\cdot 2^2 + 0\cdot 2^3$. A valid circuit assignment is therefore given by $<S_0,S_1,S_2,S_3,S_4>=<1,1,1,0,7>$ and, indeed, the assignment satisfies the required $5$ constraints including the $4$ boolean constraints for $S_0$, $\ldots$, $S_3$: 
\begin{align*}
1\cdot (1-1) &= 0 & \text{// boolean constraints}\\
1\cdot (1-1) &= 0 \\
1\cdot (1-1) &= 0 \\
0\cdot (1-0) &= 0  \\
(1 + 2 + 4 + 0 -7)\cdot 1 &= 0  & \text{// binary rep. constraint}
\end{align*}
\end{example}
\subsection{Cryptographic Primitives}
In applications, it is often required to do cryptography in a circuit. To do this, basic cryptographic primitives like hash functions or elliptic curve cryptography needs to be implemented as circuits. In this section, we give a few basic examples of how to implement such primitives. 
\subsubsection{Twisted Edwards curves} Implementing elliptic curve cryptography in circuits means to implement the defining curve equations as well as the algebraic operations, like the group law or the scalar multiplication as circuits. To do this efficiently, the curve must be defined over the same base field as the field that is used in the circuit. 

For efficiency reasons, it is advantageous to choose an elliptic curve such that that all required constraints and operations can be implement with as few gates as possible. Twisted Edwards curves are particularly useful for that matter, since their group law is particularly simple and the same calculation can be used for all curve points including the point at infinity. This simplifies the circuit a lot.
% implementations https://github.com/iden3/circomlib/blob/master/circuits/babyjub.circom
\paragraph{Twisted Edwards curve constraints} As we have seen in \ref{sec:edwards}, a twisted Edwards curve over a finite field $F$ is defined as the set of all pairs of points $(x,y)\in \F\times \F$ such that $x$ and $y$ satisfy the equation $a\cdot x^2+y^2= 1+d\cdot x^2y^2$ and as we have seen in \examplename{} \ref{ex:TJJ-circuit_1}, we can transform this equation into the following circuit:
\begin{center}
\digraph[scale=0.35]{TECCIRCUIT}{
	forcelabels=true;
	center=true;
	splines=ortho;
	nodesep= 2.0;
	n1 -> n4 [label="S_1"labeldistance="4"];
    n1 -> n4 //[ color=lightgray ]
	n2 -> n6 [label="S_2"];
	n2 -> n6 //[ color=lightgray ] ;
	n3 -> n9 /*[ color=lightgray ]*/ ;
	n4 -> n9 [taillabel="S_3", labeldistance="2" /*, color=lightgray */];
	n4 -> n13 [taillabel="S_3", labeldistance="4"];
	n5 -> n10 //[ color=lightgray ] ;
	n6 -> n10 [headlabel="S_4", labeldistance="4"];
	n6 -> n11 [taillabel="S_4", labeldistance="4" /*, color=lightgray */];
	n7 -> n11 /*[ color=lightgray ]*/ ;
	n8 -> n12 /*[ color=lightgray ]*/ ;
	n9 -> n12 /*[ color=lightgray ]*/ ;
	n10 -> n13 //[ color=lightgray ] ; 
	n11 -> n15 /*[ color=lightgray ]*/ ;
	n12 -> n14 /*[ color=lightgray ]*/ ;	
	n13 -> n14 [xlabel="S_5  "  /*, color=lightgray */];
	n14 -> n15 /*[ color=lightgray ]*/ ;
	n15 -> n16 [label="  S_6=0", labeldistance="2" /*, color=lightgray */];
	n1 [shape=box, label="x"];
	n2 [shape=box, label="y"];
	n3 [shape=box, label="-a" /*, color=lightgray */];
	n4 [label="*",  /*, color=lightgray */];
	n5 [shape=box, label="d"];
	n6 [label="*", /*, color=lightgray */];
	n7 [shape=box, label="-1" /*, color=lightgray */];
	n8 [shape=box, label="1" /*, color=lightgray */];
	n9 [label="*" /*, color=lightgray */];
	n10 [label="*"];
	n11 [label="*" /*, color=lightgray */];	
	n12 [label="+" /*, color=lightgray */];	
	n13 [label="*" /*, color=lightgray */];
	n14 [label="+" /*, color=lightgray */];
	n15 [label="+"/*, color=lightgray */];
	n16 [shape=box, label="0" /*, color=lightgray */];		
}
\end{center}
The circuit enforces the two inputs of \texttt{field} type to satisfy the twisted Edwards curve equation and, as we know from \examplename{} \ref{ex:tjj-circuit-2-tjj-R1CS}, the associated Rank-1 Constraint System is given by:
\begin{align*}
 S_1 \cdot S_1 &= S_3\\
 S_2 \cdot S_2 &= S_4\\
 (S_4\cdot d)\cdot S_3 &= S_5\\
 (-1\cdot S_4 + S_5 -a\cdot S_3 + 1)\cdot 1 &= 0
\end{align*}
\begin{exercise}
Write the circuit and associated Rank-1 Constraint System for a Weierstrass curve of a given field $\F$.
\end{exercise}
\paragraph{Twisted Edwards curve addition} As we have seen in \ref{sec:twisted_ed_group_law}, a major advantage of twisted Edwards curves is the existence of an addition law that contains no branching and is valid for all curve points. Moreover, the neutral element is not given by any auxiliary symbol but the curve point $(0,1)$. In fact, given two points $(x_1,y_1)$ and $(x_2,y_2)$ on a twisted Edwards curve, their sum is defined as
$$
(x_3,y_3) = \left(\frac{x_1y_2+y_1x_2}{1+d\cdot x_1x_2y_1y_2}, \frac{y_1y_2-a\cdot x_1x_2}{1-d\cdot x_1x_2y_1y_2}\right)
$$
% https://z.cash/technology/jubjub/
We can use the division circuit from \ref{def:division_circuit} to flatten this equation into an algebraic circuit. Inputs to the circuit are then not only the two curve points $(x_1,y_1)$ and $(x_2,y_2)$, but also the multiplicative inverses of the two denominators $inv_1 = (1+d\cdot x_1x_2y_1y_2)^{-1}$ as well as $inv_2= (1-d\cdot x_1x_2y_1y_2)^{-1}$, which any prover needs to compute outside of the circuit. We get
\begin{center}
\digraph[scale=0.5]{EDWARDSADD}{
  forcelabels=true;
  center=true;
  splines=ortho;
  //nodesep= 2.0;
  
  subgraph clusterin {
    n1 [shape=box, label="x_1"] ;
    n2 [shape=box, label="x_2"] ;
    n3 [shape=box, label="y_1"] ;
    n4 [shape=box, label="y_2"] ;
      
    n22 [shape=box, label="inv_1"] ;
    n23 [shape=box, label="inv_2"] ;
  
    color=white ;
  }
  
  subgraph clusterout {
    n29 [shape=box, label="x_3"] ;
    n30 [shape=box, label="y_3"] ;
  
    color=white ;
  }

    n5 [shape=box, label="a"] ;
    n6 [shape=box, label="d"] ;
    n7 [shape=box, label="1"] ;
    n8 [shape=box, label="-1"] ;
    
    n9 [label="*"] ; // x_1*y_2
    n10 [label="*"] ; // x_1*x_2
    n11 [label="*"] ; // y_1*x_2
    n12 [label="*"] ; // y_1*y_2
    n13 [label="*"] ; // a*(x_1*x_2)
    n14 [label="*"] ; // -a*(x_1*x_2)
    n15 [label="+"] ; // x_1*y_2 + y_1*x_2
    n16 [label="+"] ; // y_1*y_2 - a*x_1*x_2
    n17 [label="*"] ; // (x_1*x_2)*(y_1*y_2)
    n18 [label="*"] ; // d*(x_1*x_2)*(y_1*y_2)
    n19 [label="*"] ; // -d*(x_1*x_2)*(y_1*y_2)
    n20 [label="+"] ; // 1 + d*(x_1*x_2)*(y_1*y_2)
    n21 [label="+"] ; // 1 - d*(x_1*x_2)*(y_1*y_2)
    
    n24 [label="*"] ; // (1 + d*(x_1*x_2)*(y_1*y_2))*denom_1 =1 
    n25 [label="*"] ; // (1 - d*(x_1*x_2)*(y_1*y_2))*denom_2 =1 
    n26 [shape=box, label="1"] ;
    n27 [label="*"] ; // denom_1*(x_1*y_2 + y_1*x_2) 
    n28 [label="*"] ; // denom_2*(y_1*y_2 - a*x_1*x_2) 
    
    n1 -> n9 [headlabel=" S_1"];
    n1 -> n10 [taillabel="S_1"];
    n2 -> {n10, n11} [taillabel="S_2"];
    n3 -> n11 [headlabel=" S_3"];
    n3 -> n12 [taillabel="S_3"];
    n4 -> n9 [taillabel="S_4"];
    n4 -> n12 [headlabel="  S_4"];
    n5 -> n13 ;
    n6 -> n18 ;
    n7 -> {n20, n21}
    n8 -> {n14, n19} ;
    n9 -> n15 [headlabel=" S_7"] ;
    n10 -> n13 [xlabel="S_8"] ;
    n10 -> n17 [xlabel="S_8"] ;
    n11 -> n15 [xlabel="S_9"] ;
    n12 -> n16 [taillabel="S_10 "] ;  
    n12 -> n17 [xlabel="  S_10"] ;   
    n13 -> n14 ;
    n14 -> n16 ;
    n15 -> n27 ;
    n16 -> n28 ; 
    n17 -> n18 [xlabel="S_11"] ;
    n18 -> {n19, n20} ;
    n19 -> n21 ;
    n20 -> n24 ;
    n21 -> n25 ;
    n22 -> {n24, n27} [xlabel="S_5"] ;
    n23 -> {n25, n28}  [xlabel="S_6"] ;
    n24 -> n26 [xlabel="S_12=1"] ;
    n25 -> n26 [xlabel="S_13=1"] ;
    
    n27 -> n29 [xlabel="S_14"] ;
    n28 -> n30 [xlabel="S_15"] ;
    
}
\end{center}
Using the general technique from \ref{sec:circuits_associated_R1CS} to derive the associated Rank-1 Constraint System, we get the following result:
\begin{align*}
S_1 \cdot S_4 & = S_7 \\
S_1 \cdot S_2 & = S_8 \\
S_2 \cdot S_3 & = S_9 \\
S_3 \cdot S_4 & = S_{10} \\
S_8 \cdot S_{10} & = S_{11} \\
S_5 \cdot (1+ d\cdot S_{11}) & = 1 \\
S_6 \cdot (1 - d\cdot S_{11}) & = 1 \\
S_5 \cdot (S_9 + S_7) & = S_{14} \\
S_6 \cdot (S_{10} - a\cdot S_8) & = S_{15}
\end{align*}

\begin{comment}
\begin{example}[Baby-JubJub]
Considering our pen-and-paper baby-jubjub curve over from XXX\sme{add reference}. We recall from XXX\sme{add reference} that $(11,9)$ is a generator for the large prime order subgroup. We therefor already know from XXX\sme{add reference} that
$(11,9) + (7,8) = (11,9) + [3](11,9) = [4](11,9) = (2,9)$. So we execute the circuit  and get
\begin{align*}
x_1 = 11 & = S_1\\
x_2 = 7 & = S_2\\
y_1 = 9 & = S_3 \\
y_2 = 8 & = S_4 \\
1+ 8\cdot S_1\cdot S_2 \cd = 9 & = S_5 \\
y_3 = 8 & = S_6 \\
11 \cdot 8 = 10 & = S_7 \\
11 \cdot 7 =  12 & = S_8 \\
7 \cdot 9 =  11 & = S_9 \\
9 \cdot 8 = 7 & = S_{10} \\
12 \cdot 7 = 6 & = S_{11} \\
S_5 \cdot (1+ d\cdot S_{11}) & = 1 \\
S_6 \cdot (1 - d\cdot S_{11}) & = 1 \\
S_5 \cdot (S_9 + S_7) & = S_{14} \\
S_6 \cdot (S_{10} - a\cdot S_8) & = S_{15}
\end{align*}
\end{example}
\end{comment}
\begin{exercise}
Let $\F$ be a field. Define a circuit that enforces field inversion for a point of a twisted Edwards curve over $\F$.
\end{exercise}
\begin{exercise}
Write the circuit and associated Rank-1 Constraint System for a Weierstrass addition law of a given field $\F$.
\end{exercise}
\begin{comment}
\paragraph{Twisted Edwards curve inversion} Similar to elliptic curves in Weierstrass form, inversion is cheap on Edwards curves, as the negative of a curve point $-(x,y)$ is given by $(-x,y)$. A curve point $(x_2,y_2)$ is the additive inverse of another curve point $(x_1,y_1)$ precisely if the equation $(x_1,y_1) = (-x_2,y_2)$ holds. We can write this as follows:
$$
\begin{array}{lcl}
x_1 \cdot 1 &=& -x_2 \\
y_1 \cdot 1 &=& y_2
\end{array}
$$
We therefor have a statement of the form $w=(1,x_1,y_1,x_2,y_2)$ and can write the constraints into a matrix equation as
$$
\begin{pmatrix}
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0
\end{pmatrix} \begin{pmatrix} 1 \\ x_1 \\ y_1 \\ x_2 \\ y_2 \end{pmatrix}\odot
\begin{pmatrix}
1 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 0
\end{pmatrix} \begin{pmatrix} 1 \\ x_1 \\ y_1 \\ x_2 \\ y_2 \end{pmatrix} =
\begin{pmatrix}
0 & 0 & 0 & -1 & 0\\
0 & 0 & 0 & 0 & 1
\end{pmatrix} \begin{pmatrix} 1 \\ x_1 \\ y_1 \\ x_2 \\ y_2 \end{pmatrix}
$$

In addition we need the following constraints:
$$
\begin{array}{lcl}
x_1 \cdot 1 &=& -x_2 \\
y_1 \cdot 1 &=& y_2
\end{array}
$$
\end{comment}
\begin{comment}
\paragraph{Twisted Edwards curve scalar multiplication} 
% original circuit is here https://iden3-docs.readthedocs.io/en/latest/_downloads/33717d75ab84e11313cc0d8a090b636f/Baby-Jubjub.pdf

Although there are highly optimzed R1CS implementations for scal multiplication on elliptic curves, the basic idea is somewhat simple: Given an elliptic curve $E/\F_r$, a scalar $x\in \F_r$ with binary representation $(b_0,\ldots,b_m)$ and a curve point $P\in E/\F_r$, the scalar multiplication $[x]P$ can be written as
$$
[x]P = [b_0]P + [b_1]([2]P) + [b_2]([4]P) + \ldots + [b_m]([2^m] P)
$$
and since $b_j$ is either $0$ or $1$, $[b_j](kP)$ is either the neutral element of the curve or $[2^j]P$. However, $[2^j]P$ can be computed inductively by curve point doubling, since $[2^j]P= [2]([2^{j-1}]P)$.

So scalar multiplication can be reduced to a loop of length $m$, where the original curve point is repeatedly douled and added to the result, whenever the appropriate bit in the scalar is equal to one.

So to enforce that a curve point $(x_2,y_2)$ is the scalar product $[k](x_1,y_1)$ of a scalar $x\in F_r$ and a curve point $(x_1,y_1)$, we need an R1CS the defines point doubling on the curve (XXX\sme{add reference}) and an R1CS that enforces the binary representation of $x$ (XXX\sme{add reference}). 

In case of a twisted Edwards curve, we can use ordinary addition for doubling, as the constraints works for both cases (doublin is addition, where both arguments are equal). Moreover, $[b](x,y)=(b\cdot x, b\cdot y)$ for boolean $b$. Hence flattening equation XXX\sme{add reference} gives
$$
\begin{array}{lclr}
b_0\cdot x_1 &=& x_{0,1} & // [b_0]P\\
b_0\cdot y_1 &=& y_{0,1}\\

\end{array}
$$
In addition we need to constrain $(b_0,\ldots, b_N)$ to be the binary representation of $x$ and we need to constrain each $b_j$ to be boolean.

As we can see a R1CS for scalar multiplication utilizes many R1CS that we have introduced before. For efficiency and readability it is therefore useful to apply the concept of a gadget (XXX\sme{add reference}). A pseudocode method to derive the associated R1CS could look like this:

%\begin{algorithmic}
%\Require $m$ Bitlength of modulus
%\Statement $w \gets [x,b[m],mid[m]]$
%\State $tmp \gets 0$
%\For{$j\gets 1,\ldots, m$}
%	\State \textbf{Constrain:} $b[j]\cdot (1-b[j]) == 0$
%	\State \textbf{Constrain:} $b[j] \cdot 2^j == mid[j]$
%	\State $tmp = tmp + mid[j]$
%\EndFor
%\State \textbf{Constrain:} $tmp \cdot 1 == x$
%\end{algorithmic}

%\begin{codebox}
%\Procname{$\proc{Insertion-Sort}(A)$}
%\li \For $j \gets 2$ \To $\id{length}[A]$
%\li     \Do$\id{key} \gets A[j]$
%\li         \Comment Insert $A[j]$ into the sorted sequence $A[1 \twodots j-1]$.
%\li         $i \gets j-1$\li         \While $i > 0$ and $A[i] > \id{key}$
%\li             \Do$A[i+1] \gets A[i]$
%\li                 $i \gets i-1$\End
%\li         $A[i+1] \gets \id{key}$\End
%\end{codebox}
\end{comment}
 

